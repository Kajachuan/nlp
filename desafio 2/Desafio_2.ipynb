{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZd5yLnnHOK0"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Desafío 2 - Custom embedddings con Gensim\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA7nqkumo9z9"
      },
      "source": [
        "### Objetivo\n",
        "- Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.\n",
        "- Probar términos de interés y explicar similitudes en el espacio de embeddings (sacar conclusiones entre palabras similitudes y diferencias).\n",
        "- Graficarlos.\n",
        "- Obtener conclusiones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lFToQs5FK5uZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g07zJxG7H9vG"
      },
      "source": [
        "### Datos\n",
        "Utilizo como dataset los dos libros de Don Quijote de la Mancha de Miguel de Cervantes Saavedra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ticoqYD1Z3I7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d1529f87-f7fd-4f01-8973-729be301df7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0\n",
              "0      El ingenioso hidalgo don Quijote de la Mancha\n",
              "1                                               TASA\n",
              "2  Yo, Juan Gallo de Andrada, escribano de Cámara...\n",
              "3  los que residen en su Consejo, certifico y doy...\n",
              "4  los señores dél un libro intitulado El ingenio..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d9e8844-4b7c-4bd4-af52-af49ea0c8d07\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>El ingenioso hidalgo don Quijote de la Mancha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TASA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Yo, Juan Gallo de Andrada, escribano de Cámara...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>los que residen en su Consejo, certifico y doy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>los señores dél un libro intitulado El ingenio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d9e8844-4b7c-4bd4-af52-af49ea0c8d07')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d9e8844-4b7c-4bd4-af52-af49ea0c8d07 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d9e8844-4b7c-4bd4-af52-af49ea0c8d07');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1f92fc3a-f70d-458a-a146-46c41bf4dc3c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f92fc3a-f70d-458a-a146-46c41bf4dc3c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1f92fc3a-f70d-458a-a146-46c41bf4dc3c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 31619,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31434,\n        \"samples\": [\n          \"-S\\u00ed sois, amigo -respondi\\u00f3 la Trifaldi-, y tanto, que, sin vuestra\",\n          \"sobre su asno ven\\u00eda, cosa que la juzg\\u00f3 a milagro, seg\\u00fan fue lo que llevaron\",\n          \"dar m\\u00e1s cuenta a su marido, por no ponerle en alguna pendencia y trabajo. Y\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Armar el dataset utilizando salto de línea para separar las oraciones/docs\n",
        "df = pd.read_csv('quijote.txt', sep='/n', header=None, engine='python')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LEpKubK9XzXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc27926-74f6-4f40-aa32-9b7523943e1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de documentos: 31619\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de documentos:\", df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab94qaFlrA1G"
      },
      "source": [
        "### 1 - Preprocesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay que agregar a los filtros de `text_to_word_sequence` algunos símbolos extra que se utilizan en el idioma español (¡¿«»)"
      ],
      "metadata": {
        "id": "nsgd69Vo508T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rIsmMWmjrDHd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "sentence_tokens = []\n",
        "# Recorrer todas las filas y transformar las oraciones\n",
        "# en una secuencia de palabras (esto podría realizarse con NLTK o spaCy también)\n",
        "for _, row in df[:None].iterrows():\n",
        "    sentence_tokens.append(text_to_word_sequence(row[0], filters='«»¡!\"#$%&()*+,-./:;<=>¿?@[\\\\]^_`{|}~\\t\\n—'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CHepi_DGrbhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44ea8ca7-97ea-4afc-d52b-7246f6068081"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['el', 'ingenioso', 'hidalgo', 'don', 'quijote', 'de', 'la', 'mancha'],\n",
              " ['tasa'],\n",
              " ['yo',\n",
              "  'juan',\n",
              "  'gallo',\n",
              "  'de',\n",
              "  'andrada',\n",
              "  'escribano',\n",
              "  'de',\n",
              "  'cámara',\n",
              "  'del',\n",
              "  'rey',\n",
              "  'nuestro',\n",
              "  'señor',\n",
              "  'de']]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Demos un vistazo\n",
        "sentence_tokens[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaXV6nlHr5Aa"
      },
      "source": [
        "### 2 - Crear los vectores (word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OSb0v7h8r7hK"
      },
      "outputs": [],
      "source": [
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "# Durante el entrenamiento gensim por defecto no informa el \"loss\" en cada época\n",
        "# Sobrecargamos el callback para poder tener esta información\n",
        "class callback(CallbackAny2Vec):\n",
        "    \"\"\"\n",
        "    Callback to print loss after each epoch\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        loss = model.get_latest_training_loss()\n",
        "        if self.epoch == 0:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        else:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss - self.loss_previous_step))\n",
        "        self.epoch += 1\n",
        "        self.loss_previous_step = loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Skip-Gram 1 (window=2)"
      ],
      "metadata": {
        "id": "ik2mftJaLJgX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "i0wnDdv9sJ47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1e5462-066a-47d1-b928-c62c6f7b09e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de docs en el corpus: 31619\n",
            "Cantidad de words distintas en el corpus: 5299\n"
          ]
        }
      ],
      "source": [
        "# Crearmos el modelo generador de vectores\n",
        "# En este caso utilizaremos la estructura modelo Skipgram\n",
        "sg_2 = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                window=2,       # cant de palabras antes y desp de la predicha\n",
        "                vector_size=300,       # dimensionalidad de los vectores\n",
        "                negative=20,    # cantidad de negative samples... 0 es no se usa\n",
        "                workers=1,      # si tienen más cores pueden cambiar este valor\n",
        "                sg=1)           # modelo 0:CBOW  1:skipgram\n",
        "\n",
        "# Obtener el vocabulario con los tokens\n",
        "sg_2.build_vocab(sentence_tokens)\n",
        "\n",
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", sg_2.corpus_count)\n",
        "\n",
        "# Cantidad de words encontradas en el corpus\n",
        "print(\"Cantidad de words distintas en el corpus:\", len(sg_2.wv.index_to_key))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Skip-Gram 2 (window=5)"
      ],
      "metadata": {
        "id": "eq1QXcysRitt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crearmos el modelo generador de vectores\n",
        "# En este caso utilizaremos la estructura modelo Skipgram\n",
        "sg_5 = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                window=5,       # cant de palabras antes y desp de la predicha\n",
        "                vector_size=300,       # dimensionalidad de los vectores\n",
        "                negative=20,    # cantidad de negative samples... 0 es no se usa\n",
        "                workers=1,      # si tienen más cores pueden cambiar este valor\n",
        "                sg=1)           # modelo 0:CBOW  1:skipgram\n",
        "\n",
        "# Obtener el vocabulario con los tokens\n",
        "sg_5.build_vocab(sentence_tokens)\n",
        "\n",
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", sg_5.corpus_count)\n",
        "\n",
        "# Cantidad de words encontradas en el corpus\n",
        "print(\"Cantidad de words distintas en el corpus:\", len(sg_5.wv.index_to_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8JE9cUpRTp8",
        "outputId": "573069a1-4d72-4291-8e3c-0d36dd92dd9f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de docs en el corpus: 31619\n",
            "Cantidad de words distintas en el corpus: 5299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CBOW 1 (window=2)\n",
        "\n"
      ],
      "metadata": {
        "id": "VAZvJlbJRq-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crearmos el modelo generador de vectores\n",
        "# En este caso utilizaremos la estructura modelo Skipgram\n",
        "cbow_2 = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                  window=2,       # cant de palabras antes y desp de la predicha\n",
        "                  vector_size=300,       # dimensionalidad de los vectores\n",
        "                  negative=20,    # cantidad de negative samples... 0 es no se usa\n",
        "                  workers=1,      # si tienen más cores pueden cambiar este valor\n",
        "                  sg=0)           # modelo 0:CBOW  1:skipgram\n",
        "\n",
        "# Obtener el vocabulario con los tokens\n",
        "cbow_2.build_vocab(sentence_tokens)\n",
        "\n",
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", cbow_2.corpus_count)\n",
        "\n",
        "# Cantidad de words encontradas en el corpus\n",
        "print(\"Cantidad de words distintas en el corpus:\", len(cbow_2.wv.index_to_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03APdn2hRv2N",
        "outputId": "0be64175-010e-414a-9c5e-9a12a66a158f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de docs en el corpus: 31619\n",
            "Cantidad de words distintas en el corpus: 5299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CBOW 2 (window=5)"
      ],
      "metadata": {
        "id": "5KjMfL6yR8DQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crearmos el modelo generador de vectores\n",
        "# En este caso utilizaremos la estructura modelo Skipgram\n",
        "cbow_5 = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                  window=5,       # cant de palabras antes y desp de la predicha\n",
        "                  vector_size=300,       # dimensionalidad de los vectores\n",
        "                  negative=20,    # cantidad de negative samples... 0 es no se usa\n",
        "                  workers=1,      # si tienen más cores pueden cambiar este valor\n",
        "                  sg=0)           # modelo 0:CBOW  1:skipgram\n",
        "\n",
        "# Obtener el vocabulario con los tokens\n",
        "cbow_5.build_vocab(sentence_tokens)\n",
        "\n",
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", cbow_5.corpus_count)\n",
        "\n",
        "# Cantidad de words encontradas en el corpus\n",
        "print(\"Cantidad de words distintas en el corpus:\", len(cbow_5.wv.index_to_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fhNfc6OR62l",
        "outputId": "26f491ad-224d-4ab8-b754-bcfe0f004fed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de docs en el corpus: 31619\n",
            "Cantidad de words distintas en el corpus: 5299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC9mZ8DPk-UC"
      },
      "source": [
        "### 3 - Entrenar embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QSp-x0PAsq56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b661f1b-6591-4101-e9bb-13bfa94c10bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando Skip-Gram con ventana 2\n",
            "\n",
            "Loss after epoch 0: 2509553.0\n",
            "Loss after epoch 1: 1772175.0\n",
            "Loss after epoch 2: 1653907.5\n",
            "Loss after epoch 3: 1633828.5\n",
            "Loss after epoch 4: 1589399.0\n",
            "Loss after epoch 5: 1542882.0\n",
            "Loss after epoch 6: 1522711.0\n",
            "Loss after epoch 7: 1507586.0\n",
            "Loss after epoch 8: 1485059.0\n",
            "Loss after epoch 9: 1472954.0\n",
            "Loss after epoch 10: 1410393.0\n",
            "Loss after epoch 11: 1389024.0\n",
            "Loss after epoch 12: 1373740.0\n",
            "Loss after epoch 13: 1362694.0\n",
            "Loss after epoch 14: 1346404.0\n",
            "Loss after epoch 15: 1334560.0\n",
            "Loss after epoch 16: 1324560.0\n",
            "Loss after epoch 17: 1305664.0\n",
            "Loss after epoch 18: 1296300.0\n",
            "Loss after epoch 19: 1282840.0\n",
            "Loss after epoch 20: 1271840.0\n",
            "Loss after epoch 21: 1259820.0\n",
            "Loss after epoch 22: 1244202.0\n",
            "Loss after epoch 23: 1205632.0\n",
            "Loss after epoch 24: 1193092.0\n",
            "Loss after epoch 25: 1180240.0\n",
            "Loss after epoch 26: 1170280.0\n",
            "Loss after epoch 27: 1161656.0\n",
            "Loss after epoch 28: 1153872.0\n",
            "Loss after epoch 29: 1150516.0\n",
            "Loss after epoch 30: 1141052.0\n",
            "Loss after epoch 31: 1134292.0\n",
            "Loss after epoch 32: 1134220.0\n",
            "Loss after epoch 33: 1125752.0\n",
            "Loss after epoch 34: 1115512.0\n",
            "Loss after epoch 35: 1111112.0\n",
            "Loss after epoch 36: 1112628.0\n",
            "Loss after epoch 37: 1106632.0\n",
            "Loss after epoch 38: 1101668.0\n",
            "Loss after epoch 39: 1089228.0\n",
            "Loss after epoch 40: 1093740.0\n",
            "Loss after epoch 41: 1087940.0\n",
            "Loss after epoch 42: 1082700.0\n",
            "Loss after epoch 43: 1077432.0\n",
            "Loss after epoch 44: 1081520.0\n",
            "Loss after epoch 45: 1074780.0\n",
            "Loss after epoch 46: 1075044.0\n",
            "Loss after epoch 47: 1066092.0\n",
            "Loss after epoch 48: 1070212.0\n",
            "Loss after epoch 49: 1066448.0\n",
            "\n",
            "Entrenando Skip-Gram con ventana 5\n",
            "\n",
            "Loss after epoch 0: 3730145.0\n",
            "Loss after epoch 1: 2867283.5\n",
            "Loss after epoch 2: 2787211.5\n",
            "Loss after epoch 3: 2712687.0\n",
            "Loss after epoch 4: 2684303.0\n",
            "Loss after epoch 5: 2651112.0\n",
            "Loss after epoch 6: 2596922.0\n",
            "Loss after epoch 7: 2565392.0\n",
            "Loss after epoch 8: 2535668.0\n",
            "Loss after epoch 9: 2510000.0\n",
            "Loss after epoch 10: 2489224.0\n",
            "Loss after epoch 11: 2458826.0\n",
            "Loss after epoch 12: 2570478.0\n",
            "Loss after epoch 13: 2605700.0\n",
            "Loss after epoch 14: 2568492.0\n",
            "Loss after epoch 15: 2542172.0\n",
            "Loss after epoch 16: 2504276.0\n",
            "Loss after epoch 17: 2469420.0\n",
            "Loss after epoch 18: 2440244.0\n",
            "Loss after epoch 19: 2407200.0\n",
            "Loss after epoch 20: 2398104.0\n",
            "Loss after epoch 21: 2362884.0\n",
            "Loss after epoch 22: 2354968.0\n",
            "Loss after epoch 23: 2341484.0\n",
            "Loss after epoch 24: 2325604.0\n",
            "Loss after epoch 25: 2314740.0\n",
            "Loss after epoch 26: 651548.0\n",
            "Loss after epoch 27: 380360.0\n",
            "Loss after epoch 28: 373184.0\n",
            "Loss after epoch 29: 365032.0\n",
            "Loss after epoch 30: 363264.0\n",
            "Loss after epoch 31: 351944.0\n",
            "Loss after epoch 32: 344680.0\n",
            "Loss after epoch 33: 339784.0\n",
            "Loss after epoch 34: 330024.0\n",
            "Loss after epoch 35: 322216.0\n",
            "Loss after epoch 36: 315712.0\n",
            "Loss after epoch 37: 306152.0\n",
            "Loss after epoch 38: 294576.0\n",
            "Loss after epoch 39: 287464.0\n",
            "Loss after epoch 40: 283168.0\n",
            "Loss after epoch 41: 277504.0\n",
            "Loss after epoch 42: 264832.0\n",
            "Loss after epoch 43: 258680.0\n",
            "Loss after epoch 44: 250200.0\n",
            "Loss after epoch 45: 240216.0\n",
            "Loss after epoch 46: 236496.0\n",
            "Loss after epoch 47: 224824.0\n",
            "Loss after epoch 48: 220776.0\n",
            "Loss after epoch 49: 216456.0\n",
            "\n",
            "Entrenando CBOW con ventana 2\n",
            "\n",
            "Loss after epoch 0: 1200685.875\n",
            "Loss after epoch 1: 883584.25\n",
            "Loss after epoch 2: 721564.625\n",
            "Loss after epoch 3: 695359.75\n",
            "Loss after epoch 4: 681803.75\n",
            "Loss after epoch 5: 626914.25\n",
            "Loss after epoch 6: 615528.5\n",
            "Loss after epoch 7: 606142.0\n",
            "Loss after epoch 8: 594812.5\n",
            "Loss after epoch 9: 586643.0\n",
            "Loss after epoch 10: 577854.0\n",
            "Loss after epoch 11: 569898.0\n",
            "Loss after epoch 12: 542718.5\n",
            "Loss after epoch 13: 535017.0\n",
            "Loss after epoch 14: 527341.0\n",
            "Loss after epoch 15: 520751.0\n",
            "Loss after epoch 16: 515078.0\n",
            "Loss after epoch 17: 507851.0\n",
            "Loss after epoch 18: 501771.0\n",
            "Loss after epoch 19: 495716.0\n",
            "Loss after epoch 20: 491413.0\n",
            "Loss after epoch 21: 486083.0\n",
            "Loss after epoch 22: 481633.0\n",
            "Loss after epoch 23: 477053.0\n",
            "Loss after epoch 24: 471721.0\n",
            "Loss after epoch 25: 468147.0\n",
            "Loss after epoch 26: 463912.0\n",
            "Loss after epoch 27: 460593.0\n",
            "Loss after epoch 28: 456258.0\n",
            "Loss after epoch 29: 401285.0\n",
            "Loss after epoch 30: 396236.0\n",
            "Loss after epoch 31: 391988.0\n",
            "Loss after epoch 32: 389912.0\n",
            "Loss after epoch 33: 385214.0\n",
            "Loss after epoch 34: 381776.0\n",
            "Loss after epoch 35: 378626.0\n",
            "Loss after epoch 36: 374818.0\n",
            "Loss after epoch 37: 373574.0\n",
            "Loss after epoch 38: 370186.0\n",
            "Loss after epoch 39: 366430.0\n",
            "Loss after epoch 40: 365210.0\n",
            "Loss after epoch 41: 361014.0\n",
            "Loss after epoch 42: 359000.0\n",
            "Loss after epoch 43: 357640.0\n",
            "Loss after epoch 44: 354670.0\n",
            "Loss after epoch 45: 351314.0\n",
            "Loss after epoch 46: 351202.0\n",
            "Loss after epoch 47: 347606.0\n",
            "Loss after epoch 48: 347566.0\n",
            "Loss after epoch 49: 345642.0\n",
            "\n",
            "Entrenando CBOW con ventana 5\n",
            "\n",
            "Loss after epoch 0: 1157120.25\n",
            "Loss after epoch 1: 892475.875\n",
            "Loss after epoch 2: 743441.625\n",
            "Loss after epoch 3: 714082.25\n",
            "Loss after epoch 4: 699469.5\n",
            "Loss after epoch 5: 643636.0\n",
            "Loss after epoch 6: 633774.0\n",
            "Loss after epoch 7: 624954.0\n",
            "Loss after epoch 8: 616050.5\n",
            "Loss after epoch 9: 607819.0\n",
            "Loss after epoch 10: 601244.0\n",
            "Loss after epoch 11: 588868.0\n",
            "Loss after epoch 12: 565440.0\n",
            "Loss after epoch 13: 559271.0\n",
            "Loss after epoch 14: 553478.0\n",
            "Loss after epoch 15: 547988.0\n",
            "Loss after epoch 16: 542483.0\n",
            "Loss after epoch 17: 535242.0\n",
            "Loss after epoch 18: 529098.0\n",
            "Loss after epoch 19: 522312.0\n",
            "Loss after epoch 20: 520153.0\n",
            "Loss after epoch 21: 513019.0\n",
            "Loss after epoch 22: 509687.0\n",
            "Loss after epoch 23: 505838.0\n",
            "Loss after epoch 24: 501073.0\n",
            "Loss after epoch 25: 496244.0\n",
            "Loss after epoch 26: 492178.0\n",
            "Loss after epoch 27: 476161.0\n",
            "Loss after epoch 28: 436294.0\n",
            "Loss after epoch 29: 432134.0\n",
            "Loss after epoch 30: 429226.0\n",
            "Loss after epoch 31: 424266.0\n",
            "Loss after epoch 32: 422156.0\n",
            "Loss after epoch 33: 418016.0\n",
            "Loss after epoch 34: 414464.0\n",
            "Loss after epoch 35: 409680.0\n",
            "Loss after epoch 36: 406978.0\n",
            "Loss after epoch 37: 404090.0\n",
            "Loss after epoch 38: 400846.0\n",
            "Loss after epoch 39: 397904.0\n",
            "Loss after epoch 40: 395170.0\n",
            "Loss after epoch 41: 391446.0\n",
            "Loss after epoch 42: 387334.0\n",
            "Loss after epoch 43: 385560.0\n",
            "Loss after epoch 44: 382702.0\n",
            "Loss after epoch 45: 380898.0\n",
            "Loss after epoch 46: 378040.0\n",
            "Loss after epoch 47: 376352.0\n",
            "Loss after epoch 48: 374506.0\n",
            "Loss after epoch 49: 372926.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Entrenamos los modelos generadores de vectores\n",
        "# Utilizamos nuestro callback\n",
        "\n",
        "models = {\n",
        "    \"Skip-Gram con ventana 2\": sg_2,\n",
        "    \"Skip-Gram con ventana 5\": sg_5,\n",
        "    \"CBOW con ventana 2\": cbow_2,\n",
        "    \"CBOW con ventana 5\": cbow_5\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "  print(f\"Entrenando {name}\\n\")\n",
        "  model.train(sentence_tokens,\n",
        "              total_examples=model.corpus_count,\n",
        "              epochs=50,\n",
        "              compute_loss = True,\n",
        "              callbacks=[callback()]\n",
        "              )\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddT9NVuNlCAe"
      },
      "source": [
        "### 4 - Ensayar"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Skip-Gram 1"
      ],
      "metadata": {
        "id": "Sb6MhHVwV9Pt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6cHN9xGLuPEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beeef83a-468d-446d-ccdc-62a910cefd3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('don', 0.6591389775276184),\n",
              " ('jerónimo', 0.442010760307312),\n",
              " ('apaleado', 0.3935890197753906),\n",
              " ('gaspar', 0.37267908453941345),\n",
              " ('tarfe', 0.3676985800266266),\n",
              " ('sentar', 0.367477685213089),\n",
              " ('belianís', 0.3658357560634613),\n",
              " ('ésas', 0.3628139793872833),\n",
              " ('hiciéronlo', 0.3620290160179138),\n",
              " ('malparado', 0.3610021471977234)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "sg_2.wv.most_similar(positive=[\"quijote\"], topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede observar que con Skip-Gram con ventana 2, la palabra más similar a \"quijote\" es \"don\" ya que el personaje principal es \"Don Quijote\". Además se pueden observar múltiples personajes secundarios o personajes de literatura conocidos por Don Quijote junto con palabras muy utilizadas por este personaje."
      ],
      "metadata": {
        "id": "mhrnakueOjKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "sg_2.wv.most_similar(positive=[\"sancho\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjGW_rRqbNwD",
        "outputId": "94450adf-126e-46f5-e4a1-fe01a3e02886"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('panza', 0.4396946132183075),\n",
              " ('dígote', 0.4296571612358093),\n",
              " ('majadero', 0.42393758893013),\n",
              " ('ta', 0.39974963665008545),\n",
              " ('estemos', 0.394745409488678),\n",
              " ('decid', 0.39415425062179565),\n",
              " ('desesperaba', 0.3669798970222473),\n",
              " ('oyéndole', 0.3660237491130829),\n",
              " ('sentar', 0.3643604815006256),\n",
              " ('jerónimo', 0.35951119661331177)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la palabra \"sancho\" obviamente la palabra más similar en este contexto es \"panza\" por la misma razón que con \"don quijote\". También se observan palabras que comunmente menciona el personaje y emociones que el personaje posee."
      ],
      "metadata": {
        "id": "Rkxh0wtZPT1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "sg_2.wv.most_similar(positive=[\"rocinante\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtFQhFGabPx3",
        "outputId": "1572fd79-06ee-4b91-e66d-f7a99c9c1cfa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cabestro', 0.4199143350124359),\n",
              " ('seguíale', 0.415421724319458),\n",
              " ('encaminó', 0.3921724855899811),\n",
              " ('picó', 0.38516107201576233),\n",
              " ('espuelas', 0.3826594650745392),\n",
              " ('embrazando', 0.3724251091480255),\n",
              " ('abrazar', 0.37177932262420654),\n",
              " ('sostenía', 0.3687582015991211),\n",
              " ('atravesado', 0.3685321509838104),\n",
              " ('reposado', 0.3625868260860443)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede observar que para el caso de \"rocinante\" las palabras más similares están estrechamente relacionadas a los caballos, tanto equipamiento como movimientos de los caballos."
      ],
      "metadata": {
        "id": "Onu6rIjrP0q_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "47HiU5gdkdMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2973f092-aa83-49bf-906e-a21255de5247"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('rico', 0.005084389355033636),\n",
              " ('sirva', 0.0009103221236728132),\n",
              " ('escoger', -0.011759641580283642),\n",
              " ('estimación', -0.013548364862799644),\n",
              " ('desengaño', -0.013570559211075306),\n",
              " ('poca', -0.020664053037762642),\n",
              " ('poetas', -0.021028881892561913),\n",
              " ('ocho', -0.022555021569132805),\n",
              " ('echar', -0.02315581776201725),\n",
              " ('felicísimo', -0.023315472528338432)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "sg_2.wv.most_similar(negative=[\"quijote\"], topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el caso de palabras que menos se relacionan con \"quijote\" es interesante notar que son términos que realmente no tienen nada que ver con Don Quijote ya que a lo largo de la obra el mismo personaje hace referencia a su pobreza y desventuras."
      ],
      "metadata": {
        "id": "sWtYbZ2fQYR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Skip-Gram 2"
      ],
      "metadata": {
        "id": "pHUUyRR3dDsC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "428b9722-4bd0-4e4a-c3dc-f0093561dd71",
        "id": "BGnXXUwydDsD"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('don', 0.648628294467926),\n",
              " ('jerónimo', 0.37555158138275146),\n",
              " ('sancho', 0.37298208475112915),\n",
              " ('hablas', 0.3480585813522339),\n",
              " ('dígote', 0.3472543954849243),\n",
              " ('tarfe', 0.3470093607902527),\n",
              " ('ta', 0.346200168132782),\n",
              " ('religioso', 0.3454519212245941),\n",
              " ('hiciéronlo', 0.33223816752433777),\n",
              " ('álvaro', 0.3312835991382599)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "sg_5.wv.most_similar(positive=[\"quijote\"], topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al aumentar la ventana de Skip-Gram a 5 se puede observar que se modifica ligeramente la lista de palabras más relacionadas a \"quijote\" ya que ahora por ejemplo aparece \"sancho\" y algunos otros términos que menciona el quijote."
      ],
      "metadata": {
        "id": "m4DCFuYiRcwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "sg_5.wv.most_similar(positive=[\"sancho\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f265c7c-2766-4045-bd49-7a49d0de6fbc",
        "id": "SbEUMXgPdDsE"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('panza', 0.44954997301101685),\n",
              " ('quijote', 0.37298208475112915),\n",
              " ('dígote', 0.37013110518455505),\n",
              " ('estemos', 0.36586350202560425),\n",
              " ('hablas', 0.35954904556274414),\n",
              " ('majadero', 0.3571469783782959),\n",
              " ('hiciéronlo', 0.34590861201286316),\n",
              " ('que', 0.34542787075042725),\n",
              " ('jerónimo', 0.3406313359737396),\n",
              " ('decid', 0.336548388004303)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el caso de \"sancho\" también se puede ver que se agregó la palabra \"quijote\", lo que es una señal de que este modelo capturó mejor la relación entre ambos personajes."
      ],
      "metadata": {
        "id": "9g660OFLSDdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "sg_5.wv.most_similar(positive=[\"rocinante\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a8c518b-3460-4c25-fe0a-e4843a6c6458",
        "id": "vEiRTTACdDsE"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('picó', 0.44040608406066895),\n",
              " ('cabestro', 0.40236878395080566),\n",
              " ('espuelas', 0.3921803832054138),\n",
              " ('estribo', 0.3911111056804657),\n",
              " ('embrazó', 0.37345385551452637),\n",
              " ('seguíale', 0.3642861843109131),\n",
              " ('rienda', 0.36416497826576233),\n",
              " ('embrazando', 0.3596392571926117),\n",
              " ('reposado', 0.357524037361145),\n",
              " ('descortés', 0.3509603440761566)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el caso de \"rocinante\" no hay tantas palabras nuevas pero sí cambió el orden de las palabras más similares."
      ],
      "metadata": {
        "id": "V92CKIA3SpM-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4217836b-a217-4f87-cd09-05b0fcb41b41",
        "id": "gfelkwp3dDsE"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('algodón', 0.046420346945524216),\n",
              " ('batallas', 0.011000814847648144),\n",
              " ('comedias', 0.0051581114530563354),\n",
              " ('escoger', 0.0016811976674944162),\n",
              " ('ciudades', -0.004375516902655363),\n",
              " ('volviese', -0.0045248232781887054),\n",
              " ('ingenio', -0.009265159256756306),\n",
              " ('disculpa', -0.009507724083960056),\n",
              " ('tenga', -0.01216969545930624),\n",
              " ('acordó', -0.012745779938995838)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "sg_5.wv.most_similar(negative=[\"quijote\"], topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es interesante notar que cambió la lista de palabras que menos se relacionan con \"quijote\" ya que ahora hay palabras nuevas que siguen teniendo sentido en este contexto como \"comedias\" o \"ingenio\"."
      ],
      "metadata": {
        "id": "iXLelqWkTFFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CBOW 1"
      ],
      "metadata": {
        "id": "1oM-GI2mdGcn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c847ac66-9af0-4d7a-e615-99b5b7ae4eb9",
        "id": "sl5vgTqbdGco"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('luis', 0.6069381833076477),\n",
              " ('lorenzo', 0.5668205618858337),\n",
              " ('fernando', 0.5638371706008911),\n",
              " ('álvaro', 0.5618709325790405),\n",
              " ('jerónimo', 0.5509666800498962),\n",
              " ('antonio', 0.5275198817253113),\n",
              " ('gaiferos', 0.4868934154510498),\n",
              " ('vicente', 0.4326227605342865),\n",
              " ('sancho', 0.4288356304168701),\n",
              " ('diego', 0.41858264803886414)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "cbow_2.wv.most_similar(positive=[\"quijote\"], topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es interesante notar que con CBOW con una ventana de 2, las palabras que más se relacionan con \"quijote\" son en su mayoría nombres propios de otros personajes del libro y desapareció el término \"don\"."
      ],
      "metadata": {
        "id": "gg2N_W7uVcx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "cbow_2.wv.most_similar(positive=[\"sancho\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f767cf-b921-4baf-d1e4-356d0c93b467",
        "id": "tzuioASydGcq"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('teresa', 0.6100258827209473),\n",
              " ('galeote', 0.5227469205856323),\n",
              " ('ambrosio', 0.4817162752151489),\n",
              " ('paje', 0.4511835277080536),\n",
              " ('quijote', 0.4288356304168701),\n",
              " ('sanchica', 0.4251628816127777),\n",
              " ('sansón', 0.42365336418151855),\n",
              " ('caminante', 0.42229875922203064),\n",
              " ('ricote', 0.4061884582042694),\n",
              " ('bosque', 0.40286457538604736)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es interesante notar que en el caso de \"sancho\" también aparecen más nombres propios relacionados al personaje."
      ],
      "metadata": {
        "id": "NuS3IdJ6V8LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "cbow_2.wv.most_similar(positive=[\"rocinante\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8781d5d-cbdd-49fb-ce07-5d7a02dc377e",
        "id": "XPy6wwc_dGcq"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('rucio', 0.4300481677055359),\n",
              " ('subir', 0.38905659317970276),\n",
              " ('cabestro', 0.38707876205444336),\n",
              " ('asno', 0.3805701732635498),\n",
              " ('abrazar', 0.37798911333084106),\n",
              " ('galope', 0.37211552262306213),\n",
              " ('encaminó', 0.36782729625701904),\n",
              " ('atravesado', 0.35878390073776245),\n",
              " ('caballo', 0.357482373714447),\n",
              " ('riendas', 0.3463549315929413)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el caso de \"rocinante\" pasa lo mismo que en los casos anteriores ya que la palabra con la que más se relaciona es \"rucio\", el asno de Sancho Panza. De hecho, la palabra \"asno\" también se relaciona con \"rocinante\", al igual que \"caballo\"."
      ],
      "metadata": {
        "id": "PI4UPJMQWZrm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea407eb3-1116-423d-c751-71c05b877265",
        "id": "bbreBwgEdGcq"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('haciéndole', 0.27783945202827454),\n",
              " ('ciudades', 0.26492661237716675),\n",
              " ('despojos', 0.25490477681159973),\n",
              " ('mortales', 0.2476368099451065),\n",
              " ('creció', 0.23981042206287384),\n",
              " ('reprehensión', 0.23568738996982574),\n",
              " ('divinas', 0.23418255150318146),\n",
              " ('niños', 0.2289322018623352),\n",
              " ('tengamos', 0.2191506326198578),\n",
              " ('andanza', 0.21888260543346405)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "cbow_2.wv.most_similar(negative=[\"quijote\"], topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las palabras que menos se relacionan con \"quijote\" cambia en comparación a los modelos anteriores ya que parecen haber desaparecido los adjetivos y ya no es tan simple determinar si tienen sentido o no."
      ],
      "metadata": {
        "id": "poieiaNTW6zn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CBOW 2"
      ],
      "metadata": {
        "id": "QhhNGknLdKnm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4afe06c0-a747-494e-fc27-326a999b1e60",
        "id": "RtpHaQscdKnm"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('antonio', 0.5361063480377197),\n",
              " ('luis', 0.5349081158638),\n",
              " ('fernando', 0.5334556698799133),\n",
              " ('jerónimo', 0.5266017913818359),\n",
              " ('lorenzo', 0.5214809775352478),\n",
              " ('álvaro', 0.4668184220790863),\n",
              " ('gaiferos', 0.425245463848114),\n",
              " ('vicente', 0.4024867117404938),\n",
              " ('gregorio', 0.39953306317329407),\n",
              " ('diego', 0.39745011925697327)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "cbow_5.wv.most_similar(positive=[\"quijote\"], topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al aumentar la ventana de CBOW a 5 se puede ver que siguen manteniendose como palabras más relacionadas a \"quijote\" los nombres propios de otros personajes. Es interesante notar que desaparece la palabra \"sancho\" de la lista."
      ],
      "metadata": {
        "id": "TEWKc8sBXk-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "cbow_5.wv.most_similar(positive=[\"sancho\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e724eca9-91fc-4c92-e3ab-5649c909bed0",
        "id": "X4SUfHCTdKnn"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('teresa', 0.5848585963249207),\n",
              " ('galeote', 0.4552883207798004),\n",
              " ('sansón', 0.4220113158226013),\n",
              " ('licenciado', 0.41614583134651184),\n",
              " ('caminante', 0.38356268405914307),\n",
              " ('paje', 0.38196492195129395),\n",
              " ('ambrosio', 0.3710506558418274),\n",
              " ('bosque', 0.3673679530620575),\n",
              " ('labrador', 0.34853434562683105),\n",
              " ('ginés', 0.34641149640083313)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al igual que con \"quijote\", en el caso de \"sancho\" cambia ligeramente la lista de palabras, agregando algunos adjetivos del personaje."
      ],
      "metadata": {
        "id": "kkFp-Cw-X1AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "cbow_5.wv.most_similar(positive=[\"rocinante\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bde53ec-22af-4992-92d3-ec9a401dfe72",
        "id": "AbW2i9tldKnn"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cabestro', 0.4502730667591095),\n",
              " ('subir', 0.4185652732849121),\n",
              " ('rucio', 0.4171329438686371),\n",
              " ('rienda', 0.40430504083633423),\n",
              " ('asiéndole', 0.402610719203949),\n",
              " ('estribo', 0.4014948010444641),\n",
              " ('abrazar', 0.3838617503643036),\n",
              " ('sacaron', 0.3793131709098816),\n",
              " ('encaminó', 0.37881869077682495),\n",
              " ('rocín', 0.37326234579086304)]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el caso de \"rocinante\" es interesante notar que la lista de palabras obtenida es más similar a las que se obtuvo con Skip-Gram. Igualmente \"rucio\" sigue siendo una de las palabras más similares."
      ],
      "metadata": {
        "id": "Nz-1fnC1X-K3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feedcc71-2ac1-489c-fe85-862d4da0b073",
        "id": "2grlnveldKno"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('don', 0.2568643391132355),\n",
              " ('alcanzar', 0.2001873254776001),\n",
              " ('salí', 0.19099703431129456),\n",
              " ('so', 0.1905861496925354),\n",
              " ('felicísima', 0.18491026759147644),\n",
              " ('tengamos', 0.1843477487564087),\n",
              " ('aldonza', 0.18417906761169434),\n",
              " ('honesta', 0.18401111662387848),\n",
              " ('habedes', 0.1838729828596115),\n",
              " ('ofrecer', 0.18236349523067474)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "cbow_5.wv.most_similar(negative=[\"quijote\"], topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es interesante notar que con CBOW con ventana de 5, \"don\" es una de las palabras que menos se relaciona con \"quijote\". Esto puede deberse a que el modelo capturó que la palabra \"don\" en realidad es un término relacionado a la nobleza y no está muy relacionado a \"quijote\"."
      ],
      "metadata": {
        "id": "ThWR__XAYRFN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g8UVWe6lFmh"
      },
      "source": [
        "### 5 - Visualizar agrupación de vectores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "pDxEVXAivjr9"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "def reduce_dimensions(model, num_dimensions = 2):\n",
        "\n",
        "    vectors = np.asarray(model.wv.vectors)\n",
        "    labels = np.asarray(model.wv.index_to_key)\n",
        "\n",
        "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
        "    vectors = tsne.fit_transform(vectors)\n",
        "\n",
        "    return vectors, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Skip-Gram 1"
      ],
      "metadata": {
        "id": "Di7O4bPcfk76"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "NCCXtDpcugmd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "0f909ad6-0694-43c5-d78f-556fc5b7dba3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c0a8266a-1dae-4d6c-81a8-56b6c84451ed\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c0a8266a-1dae-4d6c-81a8-56b6c84451ed\")) {                    Plotly.newPlot(                        \"c0a8266a-1dae-4d6c-81a8-56b6c84451ed\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"que\",\"de\",\"y\",\"la\",\"a\",\"en\",\"el\",\"no\",\"los\",\"se\",\"con\",\"por\",\"las\",\"lo\",\"le\",\"su\",\"don\",\"del\",\"me\",\"como\",\"quijote\",\"sancho\",\"es\",\"yo\",\"m\\u00e1s\",\"si\",\"un\",\"dijo\",\"al\",\"mi\",\"para\",\"porque\",\"ni\",\"una\",\"\\u00e9l\",\"tan\",\"o\",\"todo\",\"sin\",\"as\\u00ed\",\"respondi\\u00f3\",\"se\\u00f1or\",\"ser\",\"ha\",\"sus\",\"bien\",\"hab\\u00eda\",\"pero\",\"merced\",\"esto\",\"pues\",\"vuestra\",\"qu\\u00e9\",\"todos\",\"ya\",\"cuando\",\"era\",\"te\",\"cual\",\"sino\",\"dos\",\"donde\",\"caballero\",\"fue\",\"este\",\"esta\",\"quien\",\"ella\",\"decir\",\"he\",\"muy\",\"hacer\",\"aunque\",\"dios\",\"otra\",\"aqu\\u00ed\",\"se\\u00f1ora\",\"otro\",\"m\\u00ed\",\"aquel\",\"son\",\"estaba\",\"hay\",\"os\",\"mal\",\"sobre\",\"nos\",\"cosa\",\"buen\",\"est\\u00e1\",\"verdad\",\"tal\",\"all\\u00ed\",\"tanto\",\"ver\",\"tengo\",\"luego\",\"mundo\",\"tiene\",\"mis\",\"s\\u00e9\",\"hasta\",\"alguna\",\"poco\",\"entre\",\"todas\",\"dicho\",\"dar\",\"buena\",\"ahora\",\"parte\",\"vida\",\"uno\",\"ten\\u00eda\",\"han\",\"les\",\"menos\",\"cosas\",\"lugar\",\"s\\u00ed\",\"gran\",\"soy\",\"tu\",\"eso\",\"casa\",\"aquella\",\"panza\",\"manera\",\"tiempo\",\"digo\",\"toda\",\"cura\",\"puesto\",\"mano\",\"amo\",\"dio\",\"ellos\",\"caballeros\",\"mejor\",\"mucho\",\"antes\",\"fuera\",\"puede\",\"visto\",\"ojos\",\"sea\",\"alg\\u00fan\",\"dulcinea\",\"c\\u00f3mo\",\"d\\u00eda\",\"otras\",\"tierra\",\"hecho\",\"qui\\u00e9n\",\"otros\",\"t\\u00fa\",\"quiero\",\"padre\",\"hombre\",\"aun\",\"haber\",\"cielo\",\"hab\\u00edan\",\"amigo\",\"historia\",\"vio\",\"saber\",\"camino\",\"parece\",\"estas\",\"hizo\",\"tener\",\"escudero\",\"muchas\",\"d\\u00edas\",\"mas\",\"manos\",\"cuanto\",\"desta\",\"tres\",\"fin\",\"tambi\\u00e9n\",\"dice\",\"mujer\",\"ser\\u00e1\",\"cada\",\"mesmo\",\"cabeza\",\"cuenta\",\"nuestro\",\"vos\",\"punto\",\"noche\",\"replic\\u00f3\",\"veces\",\"fuese\",\"rocinante\",\"vuesa\",\"parecer\",\"estos\",\"razones\",\"muchos\",\"duque\",\"diciendo\",\"andante\",\"s\\u00f3lo\",\"caballo\",\"despu\\u00e9s\",\"debe\",\"grande\",\"pie\",\"pod\\u00eda\",\"gusto\",\"eran\",\"vez\",\"dec\\u00eda\",\"mil\",\"primero\",\"duquesa\",\"m\\u00edo\",\"oh\",\"lleg\\u00f3\",\"mucha\",\"voz\",\"nombre\",\"duda\",\"mismo\",\"adelante\",\"mancha\",\"estaban\",\"gobernador\",\"modo\",\"desde\",\"barbero\",\"nada\",\"seg\\u00fan\",\"toboso\",\"dado\",\"estar\",\"andantes\",\"vuestro\",\"sido\",\"hija\",\"iba\",\"cuatro\",\"voluntad\",\"deseo\",\"aquellos\",\"quiso\",\"gente\"],\"x\":[-0.7778164744377136,-0.7948671579360962,-0.7940831184387207,-0.8415171504020691,-0.7922788858413696,-0.802897036075592,-0.7269765138626099,-0.6742089986801147,6.15258264541626,22.986705780029297,-0.7683980464935303,-0.8227589726448059,2.6238350868225098,-0.5944943428039551,-1.0872888565063477,-14.71318531036377,-19.03645133972168,-2.212367534637451,-1.3737536668777466,-0.8652466535568237,-19.036699295043945,7.415533542633057,1.7321199178695679,2.4066975116729736,-17.668487548828125,-3.73150372505188,-8.41757583618164,6.865501403808594,-13.224024772644043,3.8326070308685303,7.191951274871826,-0.7453100085258484,20.608718872070312,-14.607205390930176,-5.457448482513428,2.7792422771453857,0.9458672404289246,-10.691226959228516,11.668495178222656,1.499023675918579,3.796354055404663,-0.6192429065704346,13.375405311584473,-3.8338091373443604,2.9713916778564453,-4.035060405731201,-10.314151763916016,0.13004399836063385,0.8589509725570679,4.589648723602295,-0.7091823816299438,1.515224575996399,6.773971080780029,6.3209547996521,-12.641759872436523,-2.7645938396453857,-8.395103454589844,2.3482558727264404,6.71201229095459,7.147710800170898,0.1227884516119957,-6.648672580718994,19.049331665039062,-7.5778398513793945,5.035658359527588,-7.261248588562012,7.474071502685547,-9.095117568969727,0.9413808584213257,-1.3617665767669678,10.397032737731934,11.03567886352539,-3.5636472702026367,-0.7366998195648193,0.4655269384384155,-1.9918729066848755,1.5985453128814697,18.447830200195312,4.862368106842041,-3.53231143951416,7.656252384185791,-12.5712251663208,13.803951263427734,-2.376939058303833,6.497219085693359,-9.527886390686035,-14.784971237182617,11.050463676452637,9.972898483276367,-7.718545436859131,0.9777178168296814,1.0929054021835327,-6.822664260864258,-16.512401580810547,7.5577311515808105,4.307595729827881,-13.854119300842285,7.30954647064209,11.583505630493164,6.9419331550598145,1.0935386419296265,-10.366360664367676,-11.548147201538086,9.243971824645996,-3.019055128097534,2.9023284912109375,-1.1976978778839111,13.471518516540527,7.971782684326172,0.4682493209838867,-1.6740174293518066,1.363784909248352,2.1787240505218506,-8.262258529663086,13.60211181640625,22.104354858398438,-0.8029992580413818,4.719169616699219,-1.199757695198059,2.129696846008301,-5.408267974853516,13.889866828918457,3.2670938968658447,6.628175735473633,-6.018778324127197,0.17514099180698395,4.8091583251953125,-8.230623245239258,3.0954835414886475,1.766143560409546,3.8780391216278076,6.984787464141846,21.580669403076172,-8.764573097229004,2.6195380687713623,-14.88032054901123,9.224711418151855,15.260981559753418,15.225369453430176,-4.97307825088501,-3.1547393798828125,-6.867519855499268,-1.6005781888961792,7.742910861968994,-7.597064018249512,-2.6080470085144043,12.35123348236084,17.886537551879883,3.0783438682556152,-3.4483001232147217,6.217040538787842,0.33879807591438293,7.013559818267822,18.29340362548828,10.124159812927246,0.8164257407188416,0.39288821816444397,1.8506375551223755,9.1731538772583,21.041107177734375,6.301416873931885,4.372878074645996,15.77946949005127,8.553912162780762,-7.833707332611084,-13.54338550567627,3.888956308364868,1.6931809186935425,-1.5855834484100342,2.155607223510742,-11.44408893585205,10.978797912597656,7.721468925476074,12.110980987548828,9.257563591003418,-8.188895225524902,-3.0451698303222656,9.363924026489258,-8.374251365661621,-4.35377311706543,7.118766784667969,-14.037031173706055,1.0651898384094238,-0.3827134072780609,3.6760642528533936,1.7850515842437744,-8.819381713867188,-9.571470260620117,-8.662550926208496,10.968419075012207,2.971057176589966,-8.696550369262695,-8.793259620666504,5.577604293823242,0.5656443238258362,-10.293692588806152,-12.018587112426758,0.6912404298782349,8.349212646484375,6.929250717163086,2.679074287414551,9.742171287536621,-11.372428894042969,-17.227088928222656,9.629264831542969,13.64118766784668,-12.001933097839355,-10.18056583404541,12.763589859008789,6.0130133628845215,-9.510211944580078,17.986553192138672,8.840822219848633,2.3105568885803223,-13.307745933532715,-11.258708953857422,-1.3828132152557373,5.7537689208984375,-2.415803909301758,0.818405270576477,-1.3574475049972534,-10.477762222290039,8.401321411132812,-1.284575343132019,2.019864320755005,1.0802911520004272,7.638028144836426,-7.880378723144531,17.428394317626953,-14.171761512756348,6.772454738616943,17.932554244995117,-20.529661178588867,-2.282792568206787,7.966586589813232,1.4382121562957764,17.525243759155273,-3.4591917991638184,15.2781400680542,15.266989707946777,16.405635833740234,7.3719940185546875,3.8886775970458984,-9.7866792678833,-3.6492955684661865,9.729467391967773,4.467190265655518,4.912557601928711,-9.80608081817627,1.39594566822052],\"xaxis\":\"x\",\"y\":[7.265028476715088,6.8378167152404785,6.94649076461792,6.783358097076416,7.00809907913208,6.997109413146973,6.89745569229126,7.399467468261719,-19.172168731689453,7.374181747436523,6.8121867179870605,6.882096290588379,-10.415573120117188,7.659332752227783,7.354855060577393,9.904661178588867,17.838937759399414,-5.713674068450928,7.5811285972595215,6.891939163208008,17.839988708496094,17.789674758911133,12.016733169555664,15.71685791015625,15.16392993927002,10.281107902526855,-10.595925331115723,19.074384689331055,-0.9215199947357178,11.032883644104004,5.967947959899902,7.2784881591796875,8.489093780517578,-16.935199737548828,9.34988021850586,-8.111571311950684,5.029023170471191,22.8958797454834,3.438466787338257,25.44366455078125,19.312744140625,8.506443977355957,5.274370193481445,13.17149829864502,-13.96987247467041,9.769617080688477,3.4978106021881104,7.8811211585998535,15.28105354309082,12.211807250976562,7.690926551818848,15.132734298706055,2.3045127391815186,-18.984039306640625,-13.992618560791016,10.578374862670898,2.3121185302734375,15.869779586791992,10.511521339416504,12.205839157104492,-15.122122764587402,6.451602935791016,10.878006935119629,1.648820400238037,8.678077697753906,16.919939041137695,24.782480239868164,5.985544681549072,17.33637809753418,19.21514892578125,11.05567741394043,4.752158164978027,8.241442680358887,11.023072242736816,4.453825950622559,17.368623733520508,-0.5302947759628296,15.590887069702148,12.84926700592041,7.449178218841553,-8.848718643188477,0.6948561668395996,-17.66891860961914,19.7376708984375,12.936427116394043,-7.29400110244751,15.578518867492676,-1.7086231708526611,7.813422203063965,21.654190063476562,13.33720588684082,13.460083961486816,-7.185715198516846,7.263500690460205,2.047377109527588,15.13036060333252,-1.5040520429611206,10.980093955993652,21.523456573486328,-10.138079643249512,19.026275634765625,12.088215827941895,18.000646591186523,6.052883148193359,-13.571227073669434,-11.147497177124023,16.72746467590332,1.3885947465896606,14.547930717468262,19.225479125976562,1.9393792152404785,13.361651420593262,-25.61041831970215,4.864877223968506,-20.44440460205078,-6.810803413391113,11.787984848022461,-8.695252418518066,3.7010385990142822,8.63506031036377,0.6794992089271545,19.34449005126953,4.444367408752441,10.86986255645752,-0.7533990740776062,-3.776862621307373,23.815139770507812,15.517647743225098,6.3720808029174805,18.827272415161133,2.80305552482605,19.64295768737793,10.642208099365234,-5.960864543914795,13.182497024536133,-2.200626850128174,-16.004911422729492,-17.009733200073242,9.308234214782715,9.845976829528809,7.1341633796691895,9.761155128479004,14.359471321105957,7.682795524597168,-23.04072380065918,15.389060020446777,8.58797550201416,5.152429103851318,14.397665023803711,6.591248512268066,-8.221933364868164,-5.067750930786133,9.07757568359375,17.130491256713867,-16.02362060546875,21.349334716796875,19.434940338134766,5.43753719329834,12.10429573059082,-8.705453872680664,7.300129413604736,12.335236549377441,-3.7667295932769775,16.640066146850586,19.802377700805664,-1.1014190912246704,13.889569282531738,9.216897964477539,15.013168334960938,-17.966737747192383,8.21285629272461,1.2874748706817627,16.511369705200195,-7.665964603424072,-21.019437789916992,7.255932807922363,-12.263558387756348,3.5935094356536865,17.686199188232422,-20.16402244567871,-2.605452537536621,20.814294815063477,16.478296279907227,0.2239660769701004,12.481892585754395,-25.995891571044922,4.595341682434082,-5.953578948974609,8.226363182067871,23.612550735473633,16.08243751525879,3.70920991897583,-0.952102780342102,16.034561157226562,-16.695632934570312,8.708233833312988,-3.124300241470337,16.044565200805664,-6.171750068664551,-15.769618034362793,-8.58032512664795,-14.50433349609375,0.1476362645626068,-2.9054739475250244,-6.933603286743164,2.60310697555542,-7.094182968139648,3.6221654415130615,7.262583255767822,14.816743850708008,-2.7762539386749268,-14.32047176361084,-3.304421901702881,-15.446477890014648,11.051426887512207,7.1787614822387695,-21.28350257873535,10.330499649047852,0.09953467547893524,15.60655689239502,24.815969467163086,-1.6029332876205444,10.886077880859375,-1.8167335987091064,-1.649006962776184,16.126733779907227,26.40045928955078,0.5057411789894104,18.719186782836914,-15.495641708374023,13.508598327636719,7.229128360748291,4.602783679962158,9.366995811462402,12.017751693725586,7.587219715118408,5.42735481262207,2.487600803375244,3.172729253768921,-17.00612449645996,8.95576000213623,8.120260238647461,24.65631103515625,4.963016986846924,-19.095495223999023,7.281040191650391,6.629891872406006,-16.536405563354492,11.246260643005371,-3.620293140411377],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c0a8266a-1dae-4d6c-81a8-56b6c84451ed');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Graficar los embedddings en 2D\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "vecs, labels = reduce_dimensions(sg_2)\n",
        "\n",
        "MAX_WORDS=250\n",
        "fig = px.scatter(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], text=labels[:MAX_WORDS])\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comentarios:\n",
        "\n",
        "- Se puede ver en la parte superior izquierda como \"don\" y \"quijote\" están prácticamente en la misma posición.\n",
        "- Es interesante notar también en la parte inferior derecha que las palabras \"caballeros\" y \"andantes\" también están en posiciones muy cercanas.\n",
        "- También se puede observar en la parte izquierda que \"rocinante\" está cerca a \"caballo\".\n",
        "- En la parte central parecen estar agrupados los adverbios, posesivos y tipos de palabras similares."
      ],
      "metadata": {
        "id": "3Xqb5QPrZs6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Skip-Gram 2"
      ],
      "metadata": {
        "id": "iKP6PQCefpN1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "e1f1f044-5def-41e4-9508-7b30d7c60770",
        "id": "F5pRGKt5fpN2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"f8a1e304-b41d-45e0-a751-9b6a899e99a3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f8a1e304-b41d-45e0-a751-9b6a899e99a3\")) {                    Plotly.newPlot(                        \"f8a1e304-b41d-45e0-a751-9b6a899e99a3\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"que\",\"de\",\"y\",\"la\",\"a\",\"en\",\"el\",\"no\",\"los\",\"se\",\"con\",\"por\",\"las\",\"lo\",\"le\",\"su\",\"don\",\"del\",\"me\",\"como\",\"quijote\",\"sancho\",\"es\",\"yo\",\"m\\u00e1s\",\"si\",\"un\",\"dijo\",\"al\",\"mi\",\"para\",\"porque\",\"ni\",\"una\",\"\\u00e9l\",\"tan\",\"o\",\"todo\",\"sin\",\"as\\u00ed\",\"respondi\\u00f3\",\"se\\u00f1or\",\"ser\",\"ha\",\"sus\",\"bien\",\"hab\\u00eda\",\"pero\",\"merced\",\"esto\",\"pues\",\"vuestra\",\"qu\\u00e9\",\"todos\",\"ya\",\"cuando\",\"era\",\"te\",\"cual\",\"sino\",\"dos\",\"donde\",\"caballero\",\"fue\",\"este\",\"esta\",\"quien\",\"ella\",\"decir\",\"he\",\"muy\",\"hacer\",\"aunque\",\"dios\",\"otra\",\"aqu\\u00ed\",\"se\\u00f1ora\",\"otro\",\"m\\u00ed\",\"aquel\",\"son\",\"estaba\",\"hay\",\"os\",\"mal\",\"sobre\",\"nos\",\"cosa\",\"buen\",\"est\\u00e1\",\"verdad\",\"tal\",\"all\\u00ed\",\"tanto\",\"ver\",\"tengo\",\"luego\",\"mundo\",\"tiene\",\"mis\",\"s\\u00e9\",\"hasta\",\"alguna\",\"poco\",\"entre\",\"todas\",\"dicho\",\"dar\",\"buena\",\"ahora\",\"parte\",\"vida\",\"uno\",\"ten\\u00eda\",\"han\",\"les\",\"menos\",\"cosas\",\"lugar\",\"s\\u00ed\",\"gran\",\"soy\",\"tu\",\"eso\",\"casa\",\"aquella\",\"panza\",\"manera\",\"tiempo\",\"digo\",\"toda\",\"cura\",\"puesto\",\"mano\",\"amo\",\"dio\",\"ellos\",\"caballeros\",\"mejor\",\"mucho\",\"antes\",\"fuera\",\"puede\",\"visto\",\"ojos\",\"sea\",\"alg\\u00fan\",\"dulcinea\",\"c\\u00f3mo\",\"d\\u00eda\",\"otras\",\"tierra\",\"hecho\",\"qui\\u00e9n\",\"otros\",\"t\\u00fa\",\"quiero\",\"padre\",\"hombre\",\"aun\",\"haber\",\"cielo\",\"hab\\u00edan\",\"amigo\",\"historia\",\"vio\",\"saber\",\"camino\",\"parece\",\"estas\",\"hizo\",\"tener\",\"escudero\",\"muchas\",\"d\\u00edas\",\"mas\",\"manos\",\"cuanto\",\"desta\",\"tres\",\"fin\",\"tambi\\u00e9n\",\"dice\",\"mujer\",\"ser\\u00e1\",\"cada\",\"mesmo\",\"cabeza\",\"cuenta\",\"nuestro\",\"vos\",\"punto\",\"noche\",\"replic\\u00f3\",\"veces\",\"fuese\",\"rocinante\",\"vuesa\",\"parecer\",\"estos\",\"razones\",\"muchos\",\"duque\",\"diciendo\",\"andante\",\"s\\u00f3lo\",\"caballo\",\"despu\\u00e9s\",\"debe\",\"grande\",\"pie\",\"pod\\u00eda\",\"gusto\",\"eran\",\"vez\",\"dec\\u00eda\",\"mil\",\"primero\",\"duquesa\",\"m\\u00edo\",\"oh\",\"lleg\\u00f3\",\"mucha\",\"voz\",\"nombre\",\"duda\",\"mismo\",\"adelante\",\"mancha\",\"estaban\",\"gobernador\",\"modo\",\"desde\",\"barbero\",\"nada\",\"seg\\u00fan\",\"toboso\",\"dado\",\"estar\",\"andantes\",\"vuestro\",\"sido\",\"hija\",\"iba\",\"cuatro\",\"voluntad\",\"deseo\",\"aquellos\",\"quiso\",\"gente\"],\"x\":[-1.3025814294815063,-0.7466487884521484,-0.7975601553916931,-0.5673887729644775,-0.8523787260055542,-0.9134122729301453,-0.8375357389450073,-1.692306637763977,-0.1844378411769867,-0.8890329003334045,-0.7354604005813599,-1.0691324472427368,-0.44560137391090393,-1.6236729621887207,-0.9440052509307861,-0.6989313364028931,-0.6762245297431946,-0.47010886669158936,-1.9772539138793945,-0.9951425194740295,-0.6904760599136353,-1.1805776357650757,-2.354482650756836,-2.4962058067321777,-1.1968669891357422,-1.8493499755859375,-0.3455551564693451,-1.6592915058135986,-0.24481403827667236,-1.5801252126693726,-1.2159117460250854,-1.2564321756362915,-6.021157264709473,2.846315383911133,-0.9192260503768921,-0.8611699342727661,-1.0129917860031128,-1.3376215696334839,-4.0963335037231445,-0.9621196985244751,-1.935380220413208,-1.4098117351531982,-1.3739064931869507,-1.550460934638977,-0.2627866268157959,-1.40904700756073,-0.6485309600830078,-1.4470375776290894,-6.526557445526123,-1.0263773202896118,-1.3896713256835938,-6.530296802520752,-1.5497549772262573,-0.24942722916603088,-1.358508825302124,-0.8497756123542786,-0.9305103421211243,-5.046800136566162,-0.7348971962928772,-0.9615261554718018,-0.010463343001902103,-0.831819474697113,-0.9675197005271912,-0.6065512299537659,-1.0289528369903564,-1.2419118881225586,-1.206969976425171,-1.0861679315567017,-1.3436331748962402,-1.824610948562622,-0.8360273838043213,-1.12716805934906,-1.266051173210144,-1.6666816473007202,-1.0969789028167725,-1.3935409784317017,-1.1849037408828735,-0.8579691648483276,-1.8359878063201904,-0.9964987635612488,-1.2511184215545654,0.12649384140968323,-6.611885070800781,-3.3528366088867188,-1.483769178390503,2.7150914669036865,-3.3954219818115234,-1.6433454751968384,-1.3200132846832275,-0.9523205757141113,-1.9201900959014893,-1.0883969068527222,-0.41575321555137634,-1.1279783248901367,-0.8407565951347351,-1.953409194946289,-0.5075728893280029,-1.0378674268722534,-1.1013500690460205,-1.1396751403808594,-2.481412172317505,-0.12946660816669464,-1.131162405014038,-0.7986981272697449,-0.26797640323638916,-0.4221508502960205,-1.3923041820526123,-0.9611789584159851,-1.3262120485305786,-2.0728719234466553,-0.707370400428772,-1.4578558206558228,0.7756787538528442,-0.4135134220123291,-1.8263108730316162,-0.8892576694488525,-1.7177022695541382,-1.080885887145996,-0.7464920878410339,-0.9623373746871948,-0.3931458294391632,-2.723600387573242,-4.632742881774902,-2.1919913291931152,-0.918344259262085,-0.5495635867118835,-1.1862106323242188,-1.4333404302597046,-0.9660154581069946,-2.267240285873413,-0.06329236179590225,-0.976358950138092,-1.114067554473877,2.813776731491089,-0.9858063459396362,0.23122845590114594,-3.6127562522888184,-0.6425014138221741,-1.0632920265197754,-1.499371886253357,-1.024680256843567,-0.787448525428772,-2.978614568710327,-0.8184482455253601,0.12183836102485657,-2.5630106925964355,-1.6628135442733765,-6.128185272216797,-1.1708638668060303,-0.692175567150116,-2.4984989166259766,-0.22657643258571625,-0.8348995447158813,-4.332180976867676,0.00511480076238513,-4.761054515838623,-2.84102463722229,-1.433990716934204,-1.5603622198104858,-1.2914965152740479,-0.8942301869392395,-1.0505998134613037,-0.3847947418689728,-4.47416877746582,-1.0314550399780273,1.021535873413086,-1.8875499963760376,-0.36819982528686523,-1.616231918334961,1.1072611808776855,-0.4526931345462799,-1.2868679761886597,-0.7327622175216675,-4.876959800720215,-0.3266713321208954,-1.49525785446167,-0.6895807385444641,-1.6162025928497314,-0.8555305004119873,3.0869133472442627,0.12422908842563629,-1.3220640420913696,-2.442119598388672,-4.385192394256592,-2.135462760925293,-5.020452499389648,-0.9245423674583435,3.2796998023986816,-1.4754396677017212,-0.7599248290061951,-3.9691355228424072,-0.3509339988231659,0.7015633583068848,-2.474555492401123,-4.717362880706787,-0.9066824913024902,2.5356338024139404,-6.5374836921691895,-0.5566920638084412,-0.0900687724351883,-1.8996607065200806,-0.020564425736665726,-0.6928170919418335,2.797180414199829,-2.0157265663146973,-1.661608099937439,2.4513328075408936,-0.3176157772541046,-1.8142791986465454,-0.5609169006347656,1.8932210206985474,-0.8675655722618103,-1.4724169969558716,0.5848865509033203,-1.5759140253067017,-0.3428833484649658,2.462527275085449,-0.8374093174934387,-0.47472330927848816,-2.205627202987671,-3.765695571899414,1.9822192192077637,0.12247301638126373,2.7524406909942627,-5.784003734588623,-4.168394088745117,-0.8042752742767334,-0.008023202419281006,-0.11413548141717911,2.205237627029419,-1.5094776153564453,-0.8619872331619263,-0.5013145804405212,-1.2166863679885864,-2.3749852180480957,-1.4785194396972656,-6.161571502685547,-0.6902046203613281,-1.8743891716003418,-0.6450871229171753,-3.996615409851074,-1.9091838598251343,0.803176760673523,-0.5638039708137512,2.3460488319396973,-1.7202143669128418,-1.1885064840316772,0.7152056694030762,-0.5393493175506592,0.7426693439483643],\"xaxis\":\"x\",\"y\":[-0.7977712154388428,-0.6013433933258057,-0.755881667137146,-1.1162140369415283,-0.9963139891624451,-0.8011083602905273,-1.0718721151351929,-0.7697035670280457,0.9425408840179443,-1.0343269109725952,-1.0340145826339722,-0.7893004417419434,0.5365801453590393,-1.0031476020812988,-1.3275412321090698,-1.4423604011535645,-1.6982961893081665,-0.9269469380378723,-0.6767487525939941,-0.7578782439231873,-1.7003308534622192,-1.4134811162948608,-0.8018873929977417,-0.424314945936203,-0.7559874057769775,-0.8962132930755615,-1.0204176902770996,-1.4343003034591675,-1.2573264837265015,-0.9671132564544678,-0.7557265758514404,-0.7801403999328613,-0.9020534753799438,-5.032447338104248,-1.2136495113372803,-0.8412662744522095,-0.5578108429908752,-1.1813768148422241,-4.54983377456665,-1.0721995830535889,-1.157785177230835,-0.968720018863678,-0.6112392544746399,-0.527808666229248,0.3098466098308563,-1.0338414907455444,-1.326360821723938,-0.9855629205703735,-2.4356677532196045,-1.1182236671447754,-0.6719236969947815,-2.4386560916900635,-0.7201906442642212,0.2629449963569641,-0.9011949300765991,-1.0076940059661865,-1.5116153955459595,0.6970807909965515,-1.1990721225738525,-0.6422882676124573,0.5184827446937561,-0.8266379237174988,-0.6194021701812744,-1.0705047845840454,-0.8608814477920532,-1.1960667371749878,-0.7270411849021912,-0.9583606719970703,-0.815970242023468,-0.3405504524707794,-1.1508662700653076,-1.110842227935791,-0.727836012840271,-0.49734458327293396,-1.098113775253296,-0.6148781180381775,-1.1242461204528809,-1.0803468227386475,-0.8306968212127686,-1.1340067386627197,2.0996580123901367,-1.9419589042663574,-1.390304684638977,0.11735417693853378,-0.903661847114563,-1.8466532230377197,1.995267391204834,-0.9955714344978333,-0.9595615863800049,-0.8277810215950012,-0.903389573097229,-0.9134739637374878,-0.7476853132247925,-0.9072304964065552,-1.102332592010498,-0.5186580419540405,-4.896760940551758,-0.3327845633029938,-0.649316132068634,0.7276233434677124,-0.6733386516571045,5.072840213775635,-0.9892847537994385,-0.6611084938049316,0.18314754962921143,0.7460593581199646,-0.9755071997642517,-0.6552785038948059,-1.260172963142395,-0.6180403828620911,-0.44701385498046875,-0.6591176986694336,0.8528689742088318,-1.2318594455718994,1.3828296661376953,-0.4071008265018463,-0.49554499983787537,1.1235108375549316,-0.7323089241981506,-0.5654932260513306,-1.0012809038162231,-0.1181250512599945,-0.17318381369113922,-0.6945254802703857,-1.0421085357666016,-1.198527455329895,-2.0413548946380615,-0.9887893795967102,-0.9287944436073303,-0.681511640548706,-0.8897250890731812,-1.4720675945281982,-1.2403243780136108,-2.1550302505493164,-1.2114667892456055,-1.7239526510238647,-3.9774763584136963,5.350225448608398,-0.8828737735748291,-1.1731030941009521,-0.9383184313774109,-0.7942343354225159,-1.4510599374771118,-0.9544638991355896,0.7453498244285583,-0.897456169128418,-0.7450072169303894,-3.5904529094696045,-0.6762291193008423,-0.9986957907676697,3.937992572784424,-0.11811317503452301,-0.7277570962905884,3.285156011581421,2.000570774078369,0.21447356045246124,-0.7840026021003723,-0.7935681343078613,-0.8407888412475586,-0.6467992663383484,-0.5601984262466431,-0.23420283198356628,-2.097567558288574,0.1273874044418335,-1.2207742929458618,-3.5531177520751953,-0.6682149767875671,-1.2005828619003296,-0.9578909277915955,3.8074893951416016,-2.5675387382507324,-0.7815896272659302,-1.1327884197235107,-3.84079909324646,0.4224105477333069,-1.0737581253051758,-5.876281261444092,-0.968578577041626,-0.8370296955108643,3.505891799926758,-1.3277353048324585,-0.9835490584373474,-0.779952883720398,-2.394258499145508,-0.9906776547431946,-3.4123330116271973,-1.1476613283157349,-2.340277910232544,-1.0706032514572144,-3.4894416332244873,0.38855135440826416,-1.9487895965576172,-5.353710651397705,-1.2105801105499268,-3.82692289352417,-2.970304489135742,-3.2551417350769043,-2.432070732116699,-0.5882803201675415,1.285108208656311,-5.621646404266357,1.5566250085830688,-1.4830206632614136,-4.144843578338623,3.2221148014068604,-0.2920630872249603,-1.7044627666473389,-1.1122483015060425,-0.41313183307647705,-0.8679997324943542,-2.7156529426574707,-1.7875233888626099,-2.0881195068359375,2.0016560554504395,-0.9643265008926392,-3.582470655441284,3.3520331382751465,-1.1966549158096313,-3.9995534420013428,-0.9664981365203857,-1.276005744934082,-3.1525866985321045,0.05018765479326248,-4.832427978515625,-1.428382158279419,-4.615541934967041,-0.9450037479400635,-2.1555263996124268,-1.5476573705673218,1.016487956047058,-1.0776493549346924,-2.2745261192321777,-0.8150545954704285,-1.8214695453643799,-0.8882015347480774,-0.9543271660804749,-3.6038460731506348,-0.9459707736968994,-0.6542559266090393,5.353325366973877,0.379888117313385,-0.07047878950834274,-1.3136357069015503,-1.517767310142517,2.7454752922058105,-1.791977047920227,-1.1815004348754883,1.9781391620635986,-1.8946106433868408,-0.11799601465463638],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f8a1e304-b41d-45e0-a751-9b6a899e99a3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Graficar los embedddings en 2D\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "vecs, labels = reduce_dimensions(sg_5)\n",
        "\n",
        "MAX_WORDS=250\n",
        "fig = px.scatter(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], text=labels[:MAX_WORDS])\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comentarios:\n",
        "\n",
        "- Las palabras \"caballeros\" y \"andantes\" siguen en posiciones muy cercanas en la parte superior.\n",
        "- \"dulcinea\" y \"toboso\" están prácticamente en la misma posición en la parte izquierda al igual que \"vuesa\" y \"merced\".\n",
        "- Está todo bastante agrupado en el centro, pero igualmente se puede observar que \"don\" y \"quijote\" están bastante cerca."
      ],
      "metadata": {
        "id": "ZcE9F7YycSOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CBOW 1"
      ],
      "metadata": {
        "id": "QeQA0SEnfpqX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "2883b16d-c0b5-4a6a-afaf-d6203eaa3054",
        "id": "PT2RKt76fpqX"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d96ab8c2-5258-476e-84bc-e491ba3cab14\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d96ab8c2-5258-476e-84bc-e491ba3cab14\")) {                    Plotly.newPlot(                        \"d96ab8c2-5258-476e-84bc-e491ba3cab14\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"que\",\"de\",\"y\",\"la\",\"a\",\"en\",\"el\",\"no\",\"los\",\"se\",\"con\",\"por\",\"las\",\"lo\",\"le\",\"su\",\"don\",\"del\",\"me\",\"como\",\"quijote\",\"sancho\",\"es\",\"yo\",\"m\\u00e1s\",\"si\",\"un\",\"dijo\",\"al\",\"mi\",\"para\",\"porque\",\"ni\",\"una\",\"\\u00e9l\",\"tan\",\"o\",\"todo\",\"sin\",\"as\\u00ed\",\"respondi\\u00f3\",\"se\\u00f1or\",\"ser\",\"ha\",\"sus\",\"bien\",\"hab\\u00eda\",\"pero\",\"merced\",\"esto\",\"pues\",\"vuestra\",\"qu\\u00e9\",\"todos\",\"ya\",\"cuando\",\"era\",\"te\",\"cual\",\"sino\",\"dos\",\"donde\",\"caballero\",\"fue\",\"este\",\"esta\",\"quien\",\"ella\",\"decir\",\"he\",\"muy\",\"hacer\",\"aunque\",\"dios\",\"otra\",\"aqu\\u00ed\",\"se\\u00f1ora\",\"otro\",\"m\\u00ed\",\"aquel\",\"son\",\"estaba\",\"hay\",\"os\",\"mal\",\"sobre\",\"nos\",\"cosa\",\"buen\",\"est\\u00e1\",\"verdad\",\"tal\",\"all\\u00ed\",\"tanto\",\"ver\",\"tengo\",\"luego\",\"mundo\",\"tiene\",\"mis\",\"s\\u00e9\",\"hasta\",\"alguna\",\"poco\",\"entre\",\"todas\",\"dicho\",\"dar\",\"buena\",\"ahora\",\"parte\",\"vida\",\"uno\",\"ten\\u00eda\",\"han\",\"les\",\"menos\",\"cosas\",\"lugar\",\"s\\u00ed\",\"gran\",\"soy\",\"tu\",\"eso\",\"casa\",\"aquella\",\"panza\",\"manera\",\"tiempo\",\"digo\",\"toda\",\"cura\",\"puesto\",\"mano\",\"amo\",\"dio\",\"ellos\",\"caballeros\",\"mejor\",\"mucho\",\"antes\",\"fuera\",\"puede\",\"visto\",\"ojos\",\"sea\",\"alg\\u00fan\",\"dulcinea\",\"c\\u00f3mo\",\"d\\u00eda\",\"otras\",\"tierra\",\"hecho\",\"qui\\u00e9n\",\"otros\",\"t\\u00fa\",\"quiero\",\"padre\",\"hombre\",\"aun\",\"haber\",\"cielo\",\"hab\\u00edan\",\"amigo\",\"historia\",\"vio\",\"saber\",\"camino\",\"parece\",\"estas\",\"hizo\",\"tener\",\"escudero\",\"muchas\",\"d\\u00edas\",\"mas\",\"manos\",\"cuanto\",\"desta\",\"tres\",\"fin\",\"tambi\\u00e9n\",\"dice\",\"mujer\",\"ser\\u00e1\",\"cada\",\"mesmo\",\"cabeza\",\"cuenta\",\"nuestro\",\"vos\",\"punto\",\"noche\",\"replic\\u00f3\",\"veces\",\"fuese\",\"rocinante\",\"vuesa\",\"parecer\",\"estos\",\"razones\",\"muchos\",\"duque\",\"diciendo\",\"andante\",\"s\\u00f3lo\",\"caballo\",\"despu\\u00e9s\",\"debe\",\"grande\",\"pie\",\"pod\\u00eda\",\"gusto\",\"eran\",\"vez\",\"dec\\u00eda\",\"mil\",\"primero\",\"duquesa\",\"m\\u00edo\",\"oh\",\"lleg\\u00f3\",\"mucha\",\"voz\",\"nombre\",\"duda\",\"mismo\",\"adelante\",\"mancha\",\"estaban\",\"gobernador\",\"modo\",\"desde\",\"barbero\",\"nada\",\"seg\\u00fan\",\"toboso\",\"dado\",\"estar\",\"andantes\",\"vuestro\",\"sido\",\"hija\",\"iba\",\"cuatro\",\"voluntad\",\"deseo\",\"aquellos\",\"quiso\",\"gente\"],\"x\":[15.472311973571777,24.23276138305664,-5.767816543579102,-12.614758491516113,9.523170471191406,-0.9173558354377747,0.3300149142742157,23.70472526550293,-14.584440231323242,22.44251823425293,-17.28616714477539,21.471181869506836,10.474384307861328,14.60130500793457,7.738225936889648,-27.273235321044922,12.855183601379395,0.15500061213970184,32.46031951904297,11.111949920654297,-20.425853729248047,12.091409683227539,24.579185485839844,28.097633361816406,14.058963775634766,28.540016174316406,-10.016600608825684,38.25291061401367,0.2517719566822052,-27.350759506225586,23.112089157104492,15.630264282226562,15.039910316467285,-20.949934005737305,10.725868225097656,-0.4380187690258026,-3.4796767234802246,10.307950019836426,15.848846435546875,13.483489990234375,38.31535339355469,12.76274585723877,25.71469497680664,26.665355682373047,-7.213908672332764,25.066919326782227,27.061935424804688,25.220491409301758,-39.11896896362305,-4.44331693649292,29.32611656188965,-27.77846336364746,15.320657730102539,-13.069231986999512,26.37626075744629,0.3285098671913147,16.802928924560547,30.783897399902344,10.21448040008545,11.159097671508789,-21.066574096679688,6.673809051513672,6.852778911590576,15.069722175598145,18.58651351928711,-22.33272933959961,3.186047315597534,-24.998613357543945,28.444921493530273,26.35151481628418,25.30626106262207,24.357500076293945,8.210219383239746,34.237831115722656,-20.945432662963867,32.12268829345703,-31.376310348510742,-16.43730926513672,17.88811683654785,1.7258579730987549,-3.507578134536743,-3.1154229640960693,19.403362274169922,28.857152938842773,1.343013882637024,-9.99095630645752,29.09185028076172,-27.99983787536621,-1.150530219078064,26.002931594848633,-15.732263565063477,-12.605079650878906,-5.2183122634887695,-0.12345108389854431,16.41573715209961,28.696258544921875,19.374671936035156,-8.688115119934082,21.52090072631836,-6.537518501281738,31.79246711730957,19.976943969726562,-12.745058059692383,1.6503151655197144,6.578261375427246,10.872190475463867,30.273439407348633,30.3690128326416,-13.202144622802734,35.16921615600586,-27.932348251342773,-34.00450897216797,4.664902210235596,14.848040580749512,26.747512817382812,7.739928245544434,28.715139389038086,4.593594074249268,-0.7237604260444641,4.125581741333008,-22.33245277404785,34.35530471801758,-27.26868438720703,15.58168888092041,-27.978784561157227,-20.464445114135742,15.39274787902832,-25.941930770874023,2.2364399433135986,28.811254501342773,-25.926807403564453,10.658676147460938,26.040464401245117,-13.578091621398926,-32.8279914855957,16.580055236816406,-20.872583389282227,-11.491263389587402,7.817110538482666,14.422701835632324,13.851799964904785,15.639092445373535,27.484901428222656,29.165910720825195,-14.79680061340332,18.207551956176758,18.0018367767334,-18.456235885620117,14.73402214050293,0.15396316349506378,11.709959983825684,-24.401363372802734,29.816490173339844,15.450760841369629,-10.895028114318848,26.999736785888672,32.20735549926758,-32.825321197509766,6.002438068389893,-4.726580619812012,26.29718780517578,3.3067729473114014,27.051923751831055,12.532281875610352,-26.01726531982422,1.1372002363204956,28.394765853881836,-2.894104480743408,24.753679275512695,9.704512596130371,14.155051231384277,24.816082000732422,6.816401481628418,13.016026496887207,-22.433122634887695,14.899223327636719,-0.9627349376678467,14.641865730285645,-22.36186408996582,-21.459596633911133,-12.57788372039795,13.38426685333252,8.268205642700195,-36.16485595703125,24.950340270996094,11.13744068145752,1.9397755861282349,-28.851850509643555,-32.52189254760742,-14.850236892700195,34.1429328918457,0.9471645355224609,-25.655439376831055,38.314388275146484,7.94449520111084,15.966381072998047,-4.817990779876709,-27.716888427734375,6.438039779663086,-1.3745205402374268,3.5650582313537598,-18.325176239013672,10.668251037597656,-4.832901477813721,-4.498730659484863,19.848541259765625,-3.834077835083008,0.23198483884334564,25.179080963134766,-15.510339736938477,4.915128707885742,28.75912094116211,-38.0415153503418,-2.5784201622009277,-26.68777084350586,11.707290649414062,-22.20863151550293,10.532374382019043,-24.31600570678711,15.151359558105469,17.13515281677246,-2.3223464488983154,-12.925152778625488,-27.273574829101562,0.06338151544332504,-33.40928268432617,1.939663290977478,-1.7812341451644897,-24.481473922729492,0.9815567135810852,8.871274948120117,-1.9900588989257812,-1.2719266414642334,10.415958404541016,11.948384284973145,13.115157127380371,-11.90613842010498,29.835710525512695,26.61638832092285,-10.50155258178711,-5.423008441925049,28.480600357055664,-31.50557518005371,0.08399686962366104,-20.915712356567383,-34.5123291015625,-6.858415603637695,-1.3053991794586182,29.733081817626953,-26.220796585083008],\"xaxis\":\"x\",\"y\":[17.491945266723633,23.978124618530273,-11.916756629943848,7.262192249298096,2.0214667320251465,1.7985643148422241,-3.475043535232544,8.528131484985352,-31.125394821166992,21.888874053955078,-13.616743087768555,2.1346793174743652,-33.168582916259766,17.47780990600586,-6.686642169952393,23.27297019958496,28.9464054107666,-3.3385446071624756,-3.316636085510254,-2.067772626876831,29.662744522094727,29.834138870239258,-2.0595955848693848,6.840900421142578,3.546595573425293,4.398800373077393,15.627976417541504,0.09606532007455826,-3.349029064178467,23.380929946899414,2.6011335849761963,17.611427307128906,3.167046546936035,12.668506622314453,21.28304672241211,12.204644203186035,21.54972267150879,20.7747745513916,1.3435853719711304,22.278335571289062,0.20183439552783966,26.606935501098633,15.904006958007812,-25.975887298583984,-28.89191436767578,8.6619873046875,-27.296833038330078,-0.2992381751537323,11.20292854309082,1.5550141334533691,2.3865745067596436,29.071611404418945,20.17533302307129,-26.79586410522461,29.73139762878418,-16.984546661376953,-6.695631980895996,-1.7195831537246704,35.18662643432617,30.734956741333008,-34.325950622558594,9.750712394714355,28.7307186126709,-7.256675720214844,31.373693466186523,24.71392250061035,13.78244686126709,16.831737518310547,8.783947944641113,-27.098560333251953,4.953061103820801,15.697396278381348,10.90999698638916,8.295452117919922,10.709848403930664,7.129909992218018,17.262699127197266,28.816301345825195,6.507042407989502,11.358939170837402,-30.644479751586914,-6.835237503051758,-25.26401138305664,7.753211498260498,20.233028411865234,36.46733856201172,20.689607620239258,-1.4777517318725586,17.043960571289062,1.8270788192749023,20.83115577697754,26.955474853515625,5.483272075653076,4.624307632446289,15.405426979064941,-8.559854507446289,17.484445571899414,25.767667770385742,-16.892127990722656,-28.942352294921875,2.665484666824341,-19.375383377075195,9.964004516601562,35.64521026611328,-41.634029388427734,-34.23676681518555,27.005247116088867,11.075586318969727,13.407632827758789,-3.491361141204834,-0.7814719080924988,14.463364601135254,40.89741516113281,-16.665531158447266,-26.033239364624023,-6.545434474945068,-11.296736717224121,-37.66983413696289,37.43844223022461,4.980679035186768,35.238494873046875,-8.862846374511719,23.43309211730957,22.972742080688477,15.97083854675293,10.934554100036621,23.633193969726562,-1.7803791761398315,26.650699615478516,-5.230611801147461,22.12013053894043,33.753849029541016,25.11900520324707,-3.5485963821411133,16.520389556884766,-15.489799499511719,-16.452478408813477,-25.685394287109375,17.554777145385742,-1.8345251083374023,-11.957916259765625,-7.438615798950195,-19.516923904418945,27.426233291625977,-34.68619918823242,-6.19590425491333,29.834163665771484,19.020986557006836,20.438709259033203,28.36627960205078,-30.662595748901367,6.49271297454834,26.10756492614746,21.097383499145508,-26.79355239868164,-11.959236145019531,-15.02189826965332,19.117280960083008,25.26546859741211,-17.479185104370117,-28.95829200744629,38.00788879394531,-27.233680725097656,26.36259651184082,2.100433588027954,-7.541144847869873,10.38863754272461,36.94625473022461,-12.750601768493652,-33.04064178466797,-19.581920623779297,16.305999755859375,24.5459041595459,-31.682456970214844,-27.205453872680664,16.984834671020508,-40.908714294433594,16.386220932006836,24.828340530395508,-32.72819900512695,22.276992797851562,30.658260345458984,1.6356124877929688,13.233242988586426,-1.8229013681411743,-6.677586078643799,42.75022888183594,-3.9067695140838623,-1.5971641540527344,31.613054275512695,2.521059513092041,37.25252151489258,0.7371858954429626,0.20283813774585724,-39.515560150146484,-6.240548610687256,1.4207357168197632,29.012466430664062,32.81940841674805,-25.05035400390625,-42.04947280883789,-34.03239059448242,34.245643615722656,-5.014003753662109,16.750904083251953,3.9064807891845703,36.99742126464844,-17.01957130432129,-21.40266990661621,11.449451446533203,37.168678283691406,-20.027292251586914,1.368653655052185,-31.52869987487793,-2.115755319595337,-10.912792205810547,-30.786821365356445,24.458250045776367,18.35922622680664,25.657075881958008,23.751649856567383,-8.663805961608887,16.932289123535156,-4.793496608734131,39.64776611328125,1.7126517295837402,42.746341705322266,-11.10550308227539,7.6361918449401855,-15.228747367858887,29.138696670532227,26.10582160949707,-10.510927200317383,32.90290069580078,19.964771270751953,6.654181003570557,28.762739181518555,25.5113468170166,17.628610610961914,-24.686656951904297,14.827569961547852,23.942157745361328,16.308727264404297,-13.550848007202148,-32.01262664794922,13.765460968017578,23.050003051757812,-24.63376808166504,-17.79522132873535,4.661125183105469],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d96ab8c2-5258-476e-84bc-e491ba3cab14');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Graficar los embedddings en 2D\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "vecs, labels = reduce_dimensions(cbow_2)\n",
        "\n",
        "MAX_WORDS=250\n",
        "fig = px.scatter(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], text=labels[:MAX_WORDS])\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comentarios:\n",
        "\n",
        "- Es interesante notar cómo agrupa muy bien los sinónimos, como por ejemplo en la parte derecha \"dijo\", \"replicó\" y \"respondió\".\n",
        "- De igual manera se ven agrupadas todas las conjugaciones del verbo \"haber\" en la parte inferior derecha.\n",
        "- Al igual que en Skip-Gram se puede ver que \"caballeros\" y \"andantes\" siguen muy cerca.\n",
        "- Es interesante que \"don\" está cerca de \"señor\" y \"amigo\" pero también de \"sancho\"."
      ],
      "metadata": {
        "id": "SmmNwyk9c6rs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CBOW 2"
      ],
      "metadata": {
        "id": "1amA-UsWfp61"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "bc8ffa4d-927c-4fe7-a466-708cd13964d4",
        "id": "L_mCJlWmfp63"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"29f23c9b-3685-44dc-ae8c-a5adf8cbf0ff\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"29f23c9b-3685-44dc-ae8c-a5adf8cbf0ff\")) {                    Plotly.newPlot(                        \"29f23c9b-3685-44dc-ae8c-a5adf8cbf0ff\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"que\",\"de\",\"y\",\"la\",\"a\",\"en\",\"el\",\"no\",\"los\",\"se\",\"con\",\"por\",\"las\",\"lo\",\"le\",\"su\",\"don\",\"del\",\"me\",\"como\",\"quijote\",\"sancho\",\"es\",\"yo\",\"m\\u00e1s\",\"si\",\"un\",\"dijo\",\"al\",\"mi\",\"para\",\"porque\",\"ni\",\"una\",\"\\u00e9l\",\"tan\",\"o\",\"todo\",\"sin\",\"as\\u00ed\",\"respondi\\u00f3\",\"se\\u00f1or\",\"ser\",\"ha\",\"sus\",\"bien\",\"hab\\u00eda\",\"pero\",\"merced\",\"esto\",\"pues\",\"vuestra\",\"qu\\u00e9\",\"todos\",\"ya\",\"cuando\",\"era\",\"te\",\"cual\",\"sino\",\"dos\",\"donde\",\"caballero\",\"fue\",\"este\",\"esta\",\"quien\",\"ella\",\"decir\",\"he\",\"muy\",\"hacer\",\"aunque\",\"dios\",\"otra\",\"aqu\\u00ed\",\"se\\u00f1ora\",\"otro\",\"m\\u00ed\",\"aquel\",\"son\",\"estaba\",\"hay\",\"os\",\"mal\",\"sobre\",\"nos\",\"cosa\",\"buen\",\"est\\u00e1\",\"verdad\",\"tal\",\"all\\u00ed\",\"tanto\",\"ver\",\"tengo\",\"luego\",\"mundo\",\"tiene\",\"mis\",\"s\\u00e9\",\"hasta\",\"alguna\",\"poco\",\"entre\",\"todas\",\"dicho\",\"dar\",\"buena\",\"ahora\",\"parte\",\"vida\",\"uno\",\"ten\\u00eda\",\"han\",\"les\",\"menos\",\"cosas\",\"lugar\",\"s\\u00ed\",\"gran\",\"soy\",\"tu\",\"eso\",\"casa\",\"aquella\",\"panza\",\"manera\",\"tiempo\",\"digo\",\"toda\",\"cura\",\"puesto\",\"mano\",\"amo\",\"dio\",\"ellos\",\"caballeros\",\"mejor\",\"mucho\",\"antes\",\"fuera\",\"puede\",\"visto\",\"ojos\",\"sea\",\"alg\\u00fan\",\"dulcinea\",\"c\\u00f3mo\",\"d\\u00eda\",\"otras\",\"tierra\",\"hecho\",\"qui\\u00e9n\",\"otros\",\"t\\u00fa\",\"quiero\",\"padre\",\"hombre\",\"aun\",\"haber\",\"cielo\",\"hab\\u00edan\",\"amigo\",\"historia\",\"vio\",\"saber\",\"camino\",\"parece\",\"estas\",\"hizo\",\"tener\",\"escudero\",\"muchas\",\"d\\u00edas\",\"mas\",\"manos\",\"cuanto\",\"desta\",\"tres\",\"fin\",\"tambi\\u00e9n\",\"dice\",\"mujer\",\"ser\\u00e1\",\"cada\",\"mesmo\",\"cabeza\",\"cuenta\",\"nuestro\",\"vos\",\"punto\",\"noche\",\"replic\\u00f3\",\"veces\",\"fuese\",\"rocinante\",\"vuesa\",\"parecer\",\"estos\",\"razones\",\"muchos\",\"duque\",\"diciendo\",\"andante\",\"s\\u00f3lo\",\"caballo\",\"despu\\u00e9s\",\"debe\",\"grande\",\"pie\",\"pod\\u00eda\",\"gusto\",\"eran\",\"vez\",\"dec\\u00eda\",\"mil\",\"primero\",\"duquesa\",\"m\\u00edo\",\"oh\",\"lleg\\u00f3\",\"mucha\",\"voz\",\"nombre\",\"duda\",\"mismo\",\"adelante\",\"mancha\",\"estaban\",\"gobernador\",\"modo\",\"desde\",\"barbero\",\"nada\",\"seg\\u00fan\",\"toboso\",\"dado\",\"estar\",\"andantes\",\"vuestro\",\"sido\",\"hija\",\"iba\",\"cuatro\",\"voluntad\",\"deseo\",\"aquellos\",\"quiso\",\"gente\"],\"x\":[16.768939971923828,23.62565040588379,4.605138301849365,-5.65938663482666,14.358223915100098,2.7083284854888916,8.82841682434082,16.742311477661133,-23.561126708984375,3.376863956451416,2.8847994804382324,7.715517044067383,-23.25832176208496,18.79792594909668,17.184301376342773,7.545300483703613,18.370391845703125,8.832845687866211,26.614620208740234,17.104755401611328,3.4554800987243652,18.882503509521484,23.34805679321289,23.038188934326172,7.75773811340332,16.85495376586914,-12.651311874389648,21.923192977905273,8.817432403564453,23.21990394592285,32.840274810791016,16.825557708740234,16.754846572875977,-5.3525776863098145,-6.722553253173828,9.3361177444458,12.778725624084473,16.68646812438965,5.633764266967773,17.597190856933594,21.924283981323242,21.264930725097656,27.900672912597656,37.571407318115234,-23.707075119018555,15.734086990356445,38.230098724365234,16.35236167907715,15.572735786437988,12.819220542907715,19.080739974975586,19.176483154296875,21.512100219726562,-31.229307174682617,21.80304527282715,-14.394074440002441,16.19341278076172,28.464834213256836,-5.091724395751953,-7.542800426483154,-34.803226470947266,-17.718481063842773,-1.716469407081604,4.035700798034668,11.107512474060059,24.527767181396484,5.290087699890137,-3.1733992099761963,31.64156723022461,36.7754020690918,14.4080228805542,28.18303871154785,9.38774585723877,31.315155029296875,-7.421638488769531,19.610614776611328,6.236375331878662,-9.898900985717773,22.091978073120117,10.178521156311035,-27.601049423217773,7.151161193847656,36.78227233886719,27.19928550720215,7.820558547973633,-16.659149169921875,21.545045852661133,-8.667037010192871,6.9073920249938965,36.6228141784668,15.888717651367188,24.299827575683594,-15.605091094970703,15.776296615600586,27.27685546875,28.30295753479004,-0.6155728101730347,-3.231983184814453,32.45636749267578,32.5899772644043,28.59190559387207,-32.33247375488281,23.788320541381836,-13.122650146484375,-18.590959548950195,-26.25242805480957,26.578330993652344,30.656333923339844,12.124658584594727,20.448623657226562,-8.392698287963867,9.516907691955566,17.77826690673828,13.277549743652344,37.66537857055664,17.17428970336914,22.26805305480957,-30.42100715637207,-11.4636812210083,15.041213989257812,6.975659370422363,24.703279495239258,27.47706413269043,19.00689697265625,8.329608917236328,-6.652026176452637,18.839168548583984,-6.558189392089844,-1.1120010614395142,29.26905632019043,1.8574621677398682,-8.24100399017334,27.936975479125977,-4.052178382873535,12.212976455688477,10.761817932128906,-24.273942947387695,-24.37167739868164,7.752946376800537,11.50413990020752,-21.49160385131836,21.16470718383789,32.85654067993164,27.586538314819336,-34.96798324584961,20.217744827270508,10.88079833984375,-13.571476936340332,21.097352981567383,-3.6683413982391357,-26.172151565551758,-11.612228393554688,27.20596694946289,20.61162567138672,-23.090213775634766,29.086061477661133,29.01454734802246,-4.198867321014404,-4.737889766693115,16.72753143310547,37.79468536376953,-10.810388565063477,38.18398666381836,21.174781799316406,-5.378646373748779,3.5455169677734375,31.99273681640625,-20.93131446838379,23.830326080322266,-21.896949768066406,13.495279312133789,28.208595275878906,1.2265595197677612,-22.952089309692383,-36.12705612182617,14.488102912902832,-34.29840850830078,14.22501277923584,24.361984252929688,-35.627567291259766,-21.2779541015625,7.459174633026123,22.101593017578125,7.8385090827941895,32.591453552246094,-16.660062789916992,27.1785888671875,-13.846994400024414,-0.8361718058586121,-1.7925753593444824,26.92852210998535,-11.872093200683594,-5.545618057250977,21.92388916015625,-29.554813385009766,17.408405303955078,-14.912525177001953,19.174551010131836,7.491641998291016,-25.51947784423828,-33.369407653808594,-30.879623413085938,-8.969487190246582,4.281587600708008,-5.861634731292725,15.484663963317871,-14.754500389099121,-1.542880892753601,33.18933868408203,5.054793357849121,-10.02608585357666,17.555023193359375,10.866217613220215,-20.44395637512207,-8.409745216369629,10.897177696228027,-36.72591781616211,-5.397001266479492,1.5745725631713867,21.642213821411133,27.45478630065918,-18.022497177124023,6.0653886795043945,-2.4510984420776367,-4.305058479309082,17.711627960205078,27.169384002685547,-18.50265121459961,-17.742332458496094,-17.986221313476562,-3.1262998580932617,-14.487698554992676,0.27921754121780396,-7.700479984283447,11.694083213806152,21.705699920654297,-12.882749557495117,28.229524612426758,29.16919708251953,-23.736509323120117,23.18163299560547,28.43905258178711,8.249246597290039,-15.047916412353516,-35.324378967285156,10.412656784057617,8.113504409790039,-24.831008911132812,10.805479049682617,-5.521259307861328],\"xaxis\":\"x\",\"y\":[-14.49472713470459,-22.273836135864258,9.611553192138672,16.535646438598633,19.81131935119629,9.511099815368652,-36.46589660644531,-12.935929298400879,0.5798785090446472,-5.559294700622559,15.792996406555176,-15.854802131652832,12.111919403076172,-18.44121742248535,-27.45328140258789,-12.694571495056152,-19.97577667236328,-36.46929931640625,-21.01063346862793,-18.436975479125977,-31.838315963745117,-21.00484275817871,-10.905623435974121,-16.54168128967285,-11.115951538085938,-14.41087818145752,9.120530128479004,-33.7812614440918,-36.49620056152344,-15.64094066619873,6.458786487579346,-14.582535743713379,-32.347618103027344,19.845083236694336,11.3701171875,-26.130393981933594,-19.632211685180664,-11.555127143859863,-0.6537358164787292,-15.762102127075195,-33.77955627441406,-15.67578411102295,17.46106719970703,0.46197232604026794,2.343341588973999,-18.658267974853516,1.8241183757781982,-14.219710350036621,25.19875717163086,-13.309212684631348,-14.413888931274414,-29.893339157104492,-18.510616302490234,-8.133343696594238,-27.724618911743164,-9.547394752502441,-25.397537231445312,-9.438758850097656,1.6146204471588135,-29.96800994873047,-14.469094276428223,-24.855709075927734,-26.03291130065918,15.076004981994629,-32.50312423706055,-17.771268844604492,-26.78182601928711,2.726262331008911,-13.912676811218262,1.2933979034423828,-22.446945190429688,16.11968231201172,-11.060198783874512,1.5263112783432007,34.240814208984375,1.139446496963501,33.0613899230957,-16.900880813598633,-1.7194119691848755,-30.0738468170166,-11.707611083984375,18.301280975341797,-8.961165428161621,-12.954099655151367,-19.91767692565918,18.293577194213867,6.505300998687744,29.206985473632812,-21.470264434814453,-8.06928825378418,-16.641971588134766,-18.255783081054688,-22.756628036499023,-21.310819625854492,11.344836235046387,-2.719135284423828,12.472550392150879,-15.150384902954102,4.171388149261475,-1.2998709678649902,-5.356374740600586,-15.772789001464844,26.877307891845703,-15.298264503479004,7.664257049560547,14.451263427734375,-28.38740348815918,11.481290817260742,-23.632997512817383,-9.31141185760498,29.67408561706543,29.79266357421875,33.19816589355469,7.446603775024414,0.48291563987731934,-27.463485717773438,-6.646338939666748,10.989770889282227,-19.42340087890625,-20.40616226196289,-33.945518493652344,-5.457072734832764,-6.410879611968994,-15.291106224060059,34.316505432128906,34.55956268310547,-16.26026725769043,27.399940490722656,-20.528064727783203,-3.599888801574707,18.612825393676758,-27.8520450592041,-23.766557693481445,15.8041353225708,30.3277530670166,15.45042896270752,-4.733654022216797,-11.605652809143066,-9.985238075256348,-4.105928421020508,-20.328353881835938,-6.933131694793701,-7.455552577972412,-28.130752563476562,-1.6387298107147217,-5.648446083068848,-31.65546989440918,-29.99169158935547,-18.49625015258789,-19.22149658203125,13.721996307373047,29.166568756103516,-27.028343200683594,-18.334516525268555,-6.443098068237305,-7.707568645477295,-5.614914894104004,-27.381616592407227,-24.83600425720215,-32.36441421508789,2.928096055984497,-23.872604370117188,1.7764500379562378,-15.661277770996094,-34.678768157958984,14.034527778625488,-12.970646858215332,21.673612594604492,-0.7248787879943848,13.720771789550781,13.3344087600708,18.46822738647461,-22.565860748291016,18.03558349609375,-9.185564994812012,-12.202293395996094,4.621497631072998,-11.467674255371094,-18.223297119140625,-13.754733085632324,28.27544593811035,-30.9534969329834,-11.140008926391602,32.87020492553711,-5.38670539855957,-12.318094253540039,27.98975372314453,19.27668571472168,35.925758361816406,-27.946392059326172,-13.731757164001465,-20.069683074951172,26.43724822998047,-33.77900695800781,12.334694862365723,8.040626525878906,21.86551856994629,-29.89166259765625,-26.022998809814453,-1.6849894523620605,8.064805030822754,-11.674823760986328,-27.471445083618164,16.223495483398438,-10.118459701538086,-13.102839469909668,20.19315528869629,-5.8309502601623535,-10.148896217346191,-21.354549407958984,5.6642632484436035,11.102532386779785,27.612314224243164,1.4092223644256592,27.584680557250977,6.44805383682251,-12.392544746398926,-21.018735885620117,19.88047218322754,-14.1720552444458,-11.645517349243164,22.80421257019043,1.5248219966888428,19.04776954650879,-22.57646369934082,29.24833869934082,27.983015060424805,-21.691022872924805,29.5299072265625,23.993471145629883,-26.30495262145996,-24.837955474853516,10.51314926147461,-27.732641220092773,-17.979928970336914,-27.727649688720703,26.703353881835938,-26.643022537231445,18.478853225708008,-9.489962577819824,-15.679638862609863,-27.456233978271484,33.45681381225586,-2.696343183517456,-13.954354286193848,31.015579223632812,27.005157470703125,-3.6053197383880615,8.560182571411133,23.408859252929688],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('29f23c9b-3685-44dc-ae8c-a5adf8cbf0ff');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Graficar los embedddings en 2D\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "vecs, labels = reduce_dimensions(cbow_5)\n",
        "\n",
        "MAX_WORDS=250\n",
        "fig = px.scatter(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], text=labels[:MAX_WORDS])\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comentarios:\n",
        "\n",
        "- Al igual que el CBOW anterior, parece agrupar muy bien los sinónimos y conjugaciones de los mismos verbos.\n",
        "- Es interesante notar como \"don\" sigue cercano a \"sancho\" en lugar de a \"quijote\"."
      ],
      "metadata": {
        "id": "kF1E8sxJenPH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "QD3_Yq640_B-"
      },
      "outputs": [],
      "source": [
        "# También se pueden guardar los vectores y labels como tsv para graficar en\n",
        "# http://projector.tensorflow.org/\n",
        "\n",
        "import os\n",
        "\n",
        "for name, model in models.items():\n",
        "  os.mkdir(name)\n",
        "  vectors = np.asarray(model.wv.vectors)\n",
        "  labels = list(model.wv.index_to_key)\n",
        "\n",
        "  np.savetxt(f\"{name}/vectors.tsv\", vectors, delimiter=\"\\t\")\n",
        "\n",
        "  with open(f\"{name}/labels.tsv\", \"w\") as fp:\n",
        "      for item in labels:\n",
        "          fp.write(\"%s\\n\" % item)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusiones\n",
        "\n",
        "- Con Skip-Gram, se observa que logra capturar las características distintivas de los diferentes personajes del libro, pero sin relacionarlos estrechamente entre sí.\n",
        "- Por otro lado, el modelo CBOW tiende a agrupar mejor sinónimos, conjugaciones de verbos y algunos personajes, lo que sugiere que tiene una mayor capacidad para identificar relaciones semánticas.\n",
        "- Vale la pena destacar que CBOW con ventana de 5 fue el único en determinar que \"don\" no era similar a \"quijote\" a pesar de aparecer juntos en casi todo el libro. Esto resalta la habilidad de CBOW para distinguir significados en función del contexto más amplio, en lugar de simplemente basarse en la proximidad de las palabras.\n",
        "- En resumen, estos resultados sugieren que CBOW es más efectivo para agrupar palabras en función de su significado, mientras que Skip-Gram captura mejor las relaciones contextuales en las que aparecen las palabras."
      ],
      "metadata": {
        "id": "IjHsPnhMfhX-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}